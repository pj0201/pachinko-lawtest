#!/usr/bin/env python3
"""
RAGãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªãƒ†ã‚¹ãƒˆ
1. ãƒãƒƒãƒ”ãƒ³ã‚°æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ
2. èª¬æ˜æ–‡å“è³ªãƒ†ã‚¹ãƒˆ
3. è¤‡åˆèªå‡¦ç†ãƒ†ã‚¹ãƒˆ
4. ã‚½ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import json
import re
from pathlib import Path
from collections import defaultdict

def test_mapping_accuracy():
    """ãƒãƒƒãƒ”ãƒ³ã‚°ã®æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ"""

    print("\nã€ãƒ†ã‚¹ãƒˆ1: ãƒãƒƒãƒ”ãƒ³ã‚°æ­£ç¢ºæ€§ã€‘")
    print("-" * 60)

    with open('backend/rag_database_hybrid_final.json', 'r') as f:
        rag = json.load(f)

    # ãƒ†ãƒ¼ãƒã”ã¨ã«å•é¡Œã‚’æ¤œè¨¼
    theme_issues = []
    theme_coverage = defaultdict(int)

    for pid, problem in rag['problems'].items():
        theme = problem['verified_theme']
        category = problem['verified_category']
        score = problem['keyword_match_score']

        theme_coverage[theme] += 1

        # ã‚¹ã‚³ã‚¢ãŒ0ã®ãƒ†ãƒ¼ãƒã‚’ãƒã‚§ãƒƒã‚¯
        if score == 0 and theme == "å–¶æ¥­è¨±å¯ã¨å‹å¼æ¤œå®šã®é•ã„":
            theme_issues.append({
                'problem_id': pid,
                'theme': theme,
                'score': score,
                'issue': 'ã‚¼ãƒ­ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ”ãƒ³ã‚°'
            })

    print(f"âœ… ãƒ†ãƒ¼ãƒè¦†è“‹: {len(theme_coverage)}ãƒ†ãƒ¼ãƒ")
    print(f"  æœŸå¾…: 17ãƒ†ãƒ¼ãƒ")
    print(f"  çµæœ: {'OK' if len(theme_coverage) == 17 else 'NG'}")

    if theme_issues:
        print(f"\nâš ï¸  å•é¡Œæ¤œå‡º: {len(theme_issues)}ä»¶")
        for issue in theme_issues[:3]:
            print(f"  - Problem {issue['problem_id']}: {issue['issue']}")
    else:
        print(f"âœ… ãƒãƒƒãƒ”ãƒ³ã‚°ç•°å¸¸: ãªã—")

    # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒãƒã‚§ãƒƒã‚¯
    print(f"\nâœ… ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
    for cat, count in sorted(rag['statistics']['problems_by_category'].items(),
                            key=lambda x: -x[1]):
        pct = (count / 500) * 100
        print(f"  {cat:20} {count:3}å• ({pct:5.1f}%)")

    return len(theme_issues) == 0

def test_explanation_quality():
    """èª¬æ˜æ–‡å“è³ªãƒ†ã‚¹ãƒˆ"""

    print("\nã€ãƒ†ã‚¹ãƒˆ2: èª¬æ˜æ–‡å“è³ªã€‘")
    print("-" * 60)

    with open('backend/rag_database_hybrid_final.json', 'r') as f:
        rag = json.load(f)

    lengths = []
    in_range = 0
    too_short = 0
    too_long = 0

    for pid, problem in rag['problems'].items():
        length = problem['explanation_length']
        lengths.append(length)

        if 150 <= length <= 250:
            in_range += 1
        elif length < 150:
            too_short += 1
        else:
            too_long += 1

    avg_len = sum(lengths) / len(lengths)

    print(f"âœ… èª¬æ˜æ–‡é•·ã®çµ±è¨ˆ:")
    print(f"  å¹³å‡: {avg_len:.1f}æ–‡å­— (ç›®æ¨™: 150-250)")
    print(f"  ç›®æ¨™ç¯„å›²å†…: {in_range}/500å• ({(in_range/500)*100:.1f}%)")
    print(f"  çŸ­ã™ã (<150): {too_short}å•")
    print(f"  é•·ã™ã (>250): {too_long}å•")

    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print(f"\nâœ… èª¬æ˜æ–‡ã‚µãƒ³ãƒ—ãƒ«:")
    sample_pids = list(rag['problems'].keys())[:2]
    for pid in sample_pids:
        problem = rag['problems'][pid]
        exp = problem['explanation']
        print(f"  [{problem['verified_theme']}] {exp[:80]}...")

    return in_range >= 300  # 60%ä»¥ä¸ŠãŒç›®æ¨™

def test_compound_words():
    """è¤‡åˆèªå‡¦ç†ãƒ†ã‚¹ãƒˆ"""

    print("\nã€ãƒ†ã‚¹ãƒˆ3: è¤‡åˆèªå‡¦ç†ã€‘")
    print("-" * 60)

    with open('backend/rag_database_hybrid_final.json', 'r') as f:
        rag = json.load(f)

    compound_words = rag['search_config']['compound_words']

    print(f"âœ… è¤‡åˆèªè¨­å®š:")
    print(f"  ç™»éŒ²æ•°: {len(compound_words)}å€‹")
    print(f"  decompound_mode: {rag['search_config']['decompound_mode']}")

    # ä¸»è¦è¤‡åˆèªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    critical_words = ["å–¶æ¥­è¨±å¯", "å‹å¼æ¤œå®š", "å–¶æ¥­ç¦æ­¢", "ä¸æ­£æ”¹é€ "]
    all_present = all(word in compound_words for word in critical_words)

    print(f"\nâœ… ä¸»è¦è¤‡åˆèªã®ç¢ºèª:")
    for word in critical_words:
        present = "âœ“" if word in compound_words else "âœ—"
        print(f"  {present} {word}")

    print(f"\nâœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡ã¿ä»˜ã‘:")
    for kw, weight in rag['search_config']['keyword_boost'].items():
        print(f"  {kw:20} x{weight}")

    return all_present

def test_source_integration():
    """ã‚½ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ"""

    print("\nã€ãƒ†ã‚¹ãƒˆ4: ã‚½ãƒ¼ã‚¹çµ±åˆã€‘")
    print("-" * 60)

    with open('backend/rag_database_hybrid_final.json', 'r') as f:
        rag = json.load(f)

    stats = rag['statistics']['source_coverage']

    print(f"âœ… ã‚½ãƒ¼ã‚¹çµ±åˆç‡:")
    print(f"  é¢¨å–¶æ³•çµ±åˆ: {stats['with_legal_sections']:3}å• ({(stats['with_legal_sections']/500)*100:5.1f}%)")
    print(f"  è¬›ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³çµ±åˆ: {stats['with_lecture_files']:3}å• ({(stats['with_lecture_files']/500)*100:5.1f}%)")
    print(f"  ä¸¡ã‚½ãƒ¼ã‚¹çµ±åˆ: {stats['both_sources']:3}å• ({(stats['both_sources']/500)*100:5.1f}%)")

    # ãƒ†ãƒ¼ãƒåˆ¥ã‚½ãƒ¼ã‚¹ç¢ºèª
    print(f"\nâœ… ãƒ†ãƒ¼ãƒåˆ¥ã‚½ãƒ¼ã‚¹çµ±åˆ:")
    themes_with_both = 0
    themes_with_legal = 0
    themes_with_lecture = 0

    for theme_name, theme_data in rag['index']['themes'].items():
        legal = len(theme_data.get('legal_sections', []))
        lecture = len(theme_data.get('lecture_files', []))

        if legal > 0:
            themes_with_legal += 1
        if lecture > 0:
            themes_with_lecture += 1
        if legal > 0 and lecture > 0:
            themes_with_both += 1

    print(f"  æ³•å¾‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆãƒ†ãƒ¼ãƒ: {themes_with_legal}/17")
    print(f"  è¬›ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ãƒ¼ãƒ: {themes_with_lecture}/17")
    print(f"  ä¸¡ã‚½ãƒ¼ã‚¹çµ±åˆãƒ†ãƒ¼ãƒ: {themes_with_both}/17")

    return stats['with_lecture_files'] == 500  # è¬›ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³100%çµ±åˆ

def test_edge_cases():
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®æ¤œè¨¼"""

    print("\nã€ãƒ†ã‚¹ãƒˆ5: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œè¨¼ã€‘")
    print("-" * 60)

    with open('backend/rag_database_hybrid_final.json', 'r') as f:
        rag = json.load(f)

    issues = []

    for pid, problem in rag['problems'].items():
        # ç©ºã®èª¬æ˜æ–‡ãƒã‚§ãƒƒã‚¯
        if not problem['explanation'] or len(problem['explanation']) < 10:
            issues.append(f"Problem {pid}: èª¬æ˜æ–‡ãŒç©º/æ¥µåº¦ã«çŸ­ã„")

        # ãƒ†ãƒ¼ãƒã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        if not problem['verified_theme'] or not problem['verified_category']:
            issues.append(f"Problem {pid}: ãƒ†ãƒ¼ãƒ/ã‚«ãƒ†ã‚´ãƒªãŒæœªè¨­å®š")

    if issues:
        print(f"âš ï¸  æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {len(issues)}ä»¶")
        for issue in issues[:5]:
            print(f"  - {issue}")
    else:
        print(f"âœ… ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹: æ¤œå‡ºãªã—")

    # è¤‡åˆèªãƒãƒƒãƒãƒ³ã‚°ã®ç¢ºèª
    print(f"\nâœ… è¤‡åˆèªãƒãƒƒãƒãƒ³ã‚°ç¢ºèª:")
    compound_words = set(rag['search_config']['compound_words'])
    matched_in_problems = 0

    for pid, problem in rag['problems'].items():
        text = problem['problem_text']
        if any(word in text for word in compound_words):
            matched_in_problems += 1

    print(f"  è¤‡åˆèªã‚’å«ã‚€å•é¡Œ: {matched_in_problems}/500å• ({(matched_in_problems/500)*100:.1f}%)")

    return len(issues) == 0

def run_all_tests():
    """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""

    print("=" * 60)
    print("ã€RAGãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  - å“è³ªãƒ†ã‚¹ãƒˆã€‘")
    print("=" * 60)

    results = {
        'mapping': test_mapping_accuracy(),
        'explanation': test_explanation_quality(),
        'compound_words': test_compound_words(),
        'source_integration': test_source_integration(),
        'edge_cases': test_edge_cases()
    }

    print("\n" + "=" * 60)
    print("ã€ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ã€‘")
    print("=" * 60)

    passed = 0
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âš ï¸  CHECK"
        print(f"{status:10} {test_name}")
        if result:
            passed += 1

    print(f"\nç·åˆ: {passed}/{len(results)}ãƒ†ã‚¹ãƒˆåˆæ ¼")

    if passed == len(results):
        print("\nğŸ‰ RAGãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  - å“è³ªOK")
    else:
        print(f"\nâš ï¸  {len(results) - passed}ã¤ã®é …ç›®ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    run_all_tests()
