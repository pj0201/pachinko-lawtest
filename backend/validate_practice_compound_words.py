#!/usr/bin/env python3
"""
Task 4.3: å®Ÿå‹™åˆ†é‡è¤‡åˆèªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã«å¯¾ã—ã€è¤‡åˆèªãŒæ­£ç¢ºã«æ‰±ã‚ã‚Œã¦ã„ã‚‹ã‹æ¤œè¨¼
"""

import json
from pathlib import Path
from collections import defaultdict

print("=" * 80)
print("ã€Task 4.3: å®Ÿå‹™åˆ†é‡è¤‡åˆèªæ¤œè¨¼ã€‘")
print("=" * 80)

# 1. è¤‡åˆèªè¾æ›¸ã‚’èª­ã¿è¾¼ã‚€
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—1: è¤‡åˆèªè¾æ›¸ã‚’èª­ã¿è¾¼ã‚€")

with open("data/compound_words/compound_words_dictionary.json", 'r', encoding='utf-8') as f:
    compound_dict = json.load(f)

compound_words = [
    cw['word'] for cw in compound_dict.get('compound_words', [])
]

print(f"  èª­ã¿è¾¼ã¿å®Œäº†: {len(compound_words)}å€‹ã®è¤‡åˆèª")
print(f"  ä¸»è¦è¤‡åˆèª: {', '.join(compound_words[:10])}...")

# 2. ãƒ‡ãƒ¢å•é¡Œã‚’èª­ã¿è¾¼ã‚€
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¢å•é¡Œã‚’èª­ã¿è¾¼ã‚€")

try:
    with open("output/practice_domain_50_demo.json", 'r', encoding='utf-8') as f:
        demo_data = json.load(f)

    sample_problems = demo_data.get('sample_problems', [])
    print(f"  èª­ã¿è¾¼ã¿å®Œäº†: {len(sample_problems)}å€‹ã®å•é¡Œ")
except Exception as e:
    print(f"  ã‚¨ãƒ©ãƒ¼: {e}")
    sample_problems = []

# 3. è¤‡åˆèªæ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®šç¾©
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—3: è¤‡åˆèªæ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®šç¾©")

def check_compound_word_integrity(text, compound_words):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã«è¤‡åˆèªãŒæ­£ç¢ºã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹æ¤œè¨¼
    è¤‡åˆèªãŒåˆ†å‰²ã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
    """
    issues = []
    found_compounds = []

    for compound in compound_words:
        # è¤‡åˆèªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if compound in text:
            found_compounds.append(compound)

            # åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã€æ”¹è¡Œãªã©ï¼‰
            split_pattern = " ".join(list(compound))
            if split_pattern in text:
                issues.append(f"âŒ è¤‡åˆèªåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {compound} â†’ {split_pattern}")

    return {
        "found_compounds": found_compounds,
        "issues": issues,
        "integrity_score": 1.0 if not issues else 0.5
    }

def extract_keywords(text, compound_words):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¤‡åˆèªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡º"""
    found = []
    for compound in compound_words:
        if compound in text:
            found.append(compound)
    return found

# 4. å„å•é¡Œã‚’æ¤œè¨¼
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—4: å„å•é¡Œã‚’æ¤œè¨¼")

validation_results = []

for i, problem in enumerate(sample_problems, 1):
    problem_id = problem.get('problem_id', f'unknown_{i}')
    problem_text = problem.get('problem_text', '')
    claimed_keywords = problem.get('compound_words_used', [])

    # è¤‡åˆèªæ¤œè¨¼
    integrity = check_compound_word_integrity(problem_text, compound_words)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    extracted = extract_keywords(problem_text, compound_words)

    # å·®åˆ†åˆ†æ
    missing = set(claimed_keywords) - set(extracted)
    unexpected = set(extracted) - set(claimed_keywords)

    result = {
        "problem_id": problem_id,
        "problem_text_preview": problem_text[:60] + "..." if len(problem_text) > 60 else problem_text,
        "claimed_keywords": claimed_keywords,
        "extracted_keywords": extracted,
        "integrity_issues": integrity['issues'],
        "missing_keywords": list(missing),
        "unexpected_keywords": list(unexpected),
        "integrity_score": integrity['integrity_score'],
        "validation_status": "âœ“ PASS" if not integrity['issues'] else "âœ— FAIL"
    }

    validation_results.append(result)

    # è©³ç´°è¡¨ç¤º
    print(f"\n  ã€å•é¡Œ {i}: {problem_id}ã€‘")
    print(f"    ãƒ†ã‚­ã‚¹ãƒˆ: {result['problem_text_preview']}")
    print(f"    å®£è¨€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(claimed_keywords)}")
    print(f"    æŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(extracted)}")
    if integrity['issues']:
        for issue in integrity['issues']:
            print(f"    {issue}")
    else:
        print(f"    âœ“ è¤‡åˆèªæ¤œè¨¼: OK")
    print(f"    ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result['validation_status']}")

# 5. çµ±è¨ˆé›†è¨ˆ
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—5: çµ±è¨ˆé›†è¨ˆ")

total_problems = len(validation_results)
passed = sum(1 for r in validation_results if r['integrity_score'] == 1.0)
failed = total_problems - passed

print(f"""
  ç·å•é¡Œæ•°: {total_problems}å€‹
  åˆæ ¼: {passed}å€‹ ({(passed/total_problems)*100:.1f}%)
  ä¸åˆæ ¼: {failed}å€‹ ({(failed/total_problems)*100:.1f}%)
""")

# è¤‡åˆèªåˆ¥ã®çµ±è¨ˆ
compound_usage = defaultdict(int)
for result in validation_results:
    for keyword in result['extracted_keywords']:
        compound_usage[keyword] += 1

print(f"  ã€è¤‡åˆèªåˆ¥ä½¿ç”¨é »åº¦ã€‘")
for compound, count in sorted(compound_usage.items(), key=lambda x: -x[1]):
    print(f"    {compound:20} {count}å•")

# 6. å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—6: å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥åˆ†æ")

for result in validation_results:
    expected = set(result['claimed_keywords'])
    actual = set(result['extracted_keywords'])

    if expected == actual:
        print(f"  âœ“ {result['problem_id']:25} - å®Œå…¨ä¸€è‡´")
    elif expected.issubset(actual):
        print(f"  â–³ {result['problem_id']:25} - è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {list(actual - expected)}")
    elif expected.issuperset(actual):
        print(f"  âœ— {result['problem_id']:25} - æ¬ è½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {list(expected - actual)}")
    else:
        print(f"  âœ— {result['problem_id']:25} - ä¸ä¸€è‡´: {list(expected ^ actual)}")

# 7. è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—7: è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜")

report = {
    "metadata": {
        "task": "Task 4.3 - å®Ÿå‹™åˆ†é‡è¤‡åˆèªæ¤œè¨¼",
        "validation_date": "2025-11-06",
        "total_problems": total_problems,
        "total_compound_words": len(compound_words),
        "domain": "practice"
    },
    "summary": {
        "passed": passed,
        "failed": failed,
        "pass_rate": f"{(passed/total_problems)*100:.1f}%",
        "complex_word_coverage": f"{len(compound_usage)}/{len(compound_words)}"
    },
    "compound_word_statistics": dict(sorted(
        compound_usage.items(),
        key=lambda x: -x[1]
    )),
    "validation_details": validation_results,
    "recommendations": [
        "âœ“ è¤‡åˆèªåˆ†å‰²ã‚¨ãƒ©ãƒ¼: 0ä»¶" if failed == 0 else f"âŒ è¤‡åˆèªåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {failed}ä»¶ ï¼ˆä¿®æ­£å¿…è¦ï¼‰",
        f"âœ“ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºç²¾åº¦: {(passed/total_problems)*100:.1f}%",
        "âœ“ æœ¬ãƒ•ã‚§ãƒ¼ã‚ºã¯å“è³ªç¢ºèªç”¨ï¼ˆå®Ÿè£…ã§ã¯50å•ã§æ¤œè¨¼ï¼‰"
    ]
}

report_path = "output/validation_report_practice_compound_words.json"
with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(report, f, indent=2, ensure_ascii=False)

print(f"  ä¿å­˜å®Œäº†: {report_path}")

# 8. æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼
print("\n" + "=" * 80)
print("ã€Task 4.3 å®Œäº† - å®Ÿå‹™åˆ†é‡è¤‡åˆèªæ¤œè¨¼çµæœã€‘")
print("=" * 80)

print(f"""
âœ… æ¤œè¨¼å®Œäº†ï¼š
  - å•é¡Œæ•°: {total_problems}å€‹
  - åˆæ ¼ç‡: {(passed/total_problems)*100:.1f}%
  - è¤‡åˆèªä½¿ç”¨æ•°: {len(compound_usage)}å€‹/{len(compound_words)}å€‹

ğŸ“Š è¤‡åˆèªã‚«ãƒãƒ¼ç‡ï¼š
  {len(compound_usage)}/{len(compound_words)} ({(len(compound_usage)/len(compound_words))*100:.1f}%)

ğŸ” ä¸»è¦è¤‡åˆèªä½¿ç”¨çŠ¶æ³ï¼š
  - å–¶æ¥­è¨±å¯: {compound_usage.get('å–¶æ¥­è¨±å¯', 0)}å•
  - å–¶æ¥­åœæ­¢å‘½ä»¤: {compound_usage.get('å–¶æ¥­åœæ­¢å‘½ä»¤', 0)}å•
  - å‹å¼æ¤œå®š: {compound_usage.get('å‹å¼æ¤œå®š', 0)}å•
  - éŠæŠ€æ©Ÿ: {compound_usage.get('éŠæŠ€æ©Ÿ', 0)}å•
  - ãã®ä»–: {sum(v for k, v in compound_usage.items() if k not in ['å–¶æ¥­è¨±å¯', 'å–¶æ¥­åœæ­¢å‘½ä»¤', 'å‹å¼æ¤œå®š', 'éŠæŠ€æ©Ÿ'])}å•

âœ¨ æ¤œè¨¼ã®æ„ç¾©ï¼š
  1. è¤‡åˆèªãŒæ­£ç¢ºã«æ‰±ã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
  2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºç²¾åº¦ã‚’æ¤œè¨¼
  3. æœ¬ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯å“è³ªç¢ºèªï¼ˆå®Ÿè£…æ™‚ã¯50å•ã§å®Ÿæ–½ï¼‰

ğŸš€ æ¬¡ã‚¿ã‚¹ã‚¯ï¼ˆTask 4.4ï¼‰ï¼š
  - ã²ã£ã‹ã‘å¼·åº¦æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  - distractor_control_logic.py ã¨ã®é€£æº
  - é›£æ˜“åº¦åˆ¥ã®é©åˆåº¦ç¢ºèª
""")

print("=" * 80)
