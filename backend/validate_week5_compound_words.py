#!/usr/bin/env python3
"""
Task 5.5: Week 5 è¤‡åˆèªæ¤œè¨¼

ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œï¼ˆ6å•ï¼‰ã«å¯¾ã—ã¦ã€
è¤‡åˆèªã®æ­£ç¢ºæ€§ãƒ»åˆ†å‰²ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
"""

import json
import re
from pathlib import Path
from collections import defaultdict

print("=" * 80)
print("ã€Task 5.5: Week 5 è¤‡åˆèªæ¤œè¨¼ã€‘")
print("=" * 80)

# 1. è¤‡åˆèªè¾æ›¸ã¨ç”Ÿæˆå•é¡Œã‚’èª­ã¿è¾¼ã‚€
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€")

# è¤‡åˆèªè¾æ›¸
compound_words_dict = {}
try:
    with open("data/compound_words/compound_words_dictionary.json", 'r', encoding='utf-8') as f:
        data = json.load(f)
        for word_dict in data.get("compound_words", []):
            word = word_dict.get("word", "")
            compound_words_dict[word] = word_dict

    print(f"  âœ“ è¤‡åˆèªè¾æ›¸: {len(compound_words_dict)}å€‹èª­ã¿è¾¼ã¿")
except Exception as e:
    print(f"  âœ— è¤‡åˆèªè¾æ›¸èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

# ç”Ÿæˆæ¸ˆã¿å•é¡Œ
demo_problems = []
try:
    with open("output/week5_domain_generation_prepared.json", 'r', encoding='utf-8') as f:
        data = json.load(f)
        all_demo = data.get("demo_problems", {})
        for domain, problems in all_demo.items():
            demo_problems.extend(problems)

    print(f"  âœ“ ãƒ‡ãƒ¢å•é¡Œ: {len(demo_problems)}å•èª­ã¿è¾¼ã¿")
except Exception as e:
    print(f"  âœ— ãƒ‡ãƒ¢å•é¡Œèª­ã¿è¾¼ã¿å¤±æ•—: {e}")

# 2. è¤‡åˆèªæ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—2: è¤‡åˆèªæ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®šç¾©")

def check_compound_word_decomposition(text, compound_words_list):
    """è¤‡åˆèªãŒä¸æ­£ã«åˆ†å‰²ã•ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯"""
    errors = []

    for word in compound_words_list:
        if word not in text:
            continue

        # ä¸æ­£ãªåˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for char in word:
            if re.search(rf"{char}[^{word[1:]}]*?{word[1:]}", text):
                # åˆ†å‰²ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§
                if char + " " in text.replace(word, ""):
                    errors.append({
                        "word": word,
                        "error_type": "decomposition",
                        "detail": f"'{word}' ãŒåˆ†å‰²ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹"
                    })
                    break

    return errors

def extract_keywords(text, compound_words_list):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¤‡åˆèªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡º"""
    found_keywords = []

    for word in compound_words_list:
        if word in text:
            found_keywords.append(word)

    return found_keywords

def analyze_problem(problem, compound_words_list):
    """å•é¡Œå…¨ä½“ã®è¤‡åˆèªä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ"""
    # å•é¡Œæ–‡ + é¸æŠè‚¢ + èª¬æ˜æ–‡ã‚’çµåˆ
    full_text = ""
    full_text += problem.get("question", "") + " "
    full_text += " ".join(problem.get("options", {}).values()) + " "
    full_text += problem.get("explanation", "")

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    extracted_keywords = extract_keywords(full_text, compound_words_list)

    # åˆ†å‰²ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
    decomp_errors = check_compound_word_decomposition(full_text, compound_words_list)

    # å®£è¨€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ
    declared_keywords = problem.get("compound_words_used", [])
    missing_keywords = set(declared_keywords) - set(extracted_keywords)
    extra_keywords = set(extracted_keywords) - set(declared_keywords)

    return {
        "extracted": extracted_keywords,
        "declared": declared_keywords,
        "missing": list(missing_keywords),
        "extra": list(extra_keywords),
        "decomposition_errors": decomp_errors,
        "accuracy": len(missing_keywords) == 0 and len(decomp_errors) == 0
    }

print("  æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯å®šç¾©å®Œäº†")

# 3. è¤‡åˆèªæ¤œè¨¼å®Ÿè¡Œ
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—3: è¤‡åˆèªæ¤œè¨¼ã‚’å®Ÿè¡Œ")

validation_results = []
category_stats = defaultdict(lambda: {"pass": 0, "fail": 0, "errors": []})
total_pass = 0
total_fail = 0

compound_words_list = list(compound_words_dict.keys())

for problem in demo_problems:
    problem_id = problem.get("problem_id", "unknown")
    category = problem.get("category", "unknown")

    analysis = analyze_problem(problem, compound_words_list)

    result = {
        "problem_id": problem_id,
        "category": category,
        "analysis": analysis,
        "status": "PASS" if analysis["accuracy"] else "FAIL"
    }

    validation_results.append(result)

    if analysis["accuracy"]:
        category_stats[category]["pass"] += 1
        total_pass += 1
        status_mark = "âœ“"
    else:
        category_stats[category]["fail"] += 1
        total_fail += 1
        status_mark = "âœ—"
        category_stats[category]["errors"].append({
            "problem_id": problem_id,
            "issues": analysis
        })

    print(f"  {status_mark} {problem_id:35} ({', '.join(analysis['extracted'][:2])}...)")

# 4. çµ±è¨ˆæƒ…å ±
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—4: çµ±è¨ˆé›†è¨ˆ")

total_problems = len(demo_problems)
pass_rate = (total_pass / total_problems * 100) if total_problems > 0 else 0

print(f"""
  æ¤œè¨¼å¯¾è±¡: {total_problems}å•
  åˆæ ¼: {total_pass}å• ({pass_rate:.1f}%)
  ä¸åˆæ ¼: {total_fail}å•

  ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœã€‘
""")

for category in sorted(category_stats.keys()):
    stats = category_stats[category]
    total = stats["pass"] + stats["fail"]
    cat_rate = (stats["pass"] / total * 100) if total > 0 else 0
    print(f"    {category:20} {stats['pass']:2}/{total:2} ({cat_rate:5.1f}%)")

# 5. è¤‡åˆèªä½¿ç”¨é »åº¦åˆ†æ
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—5: è¤‡åˆèªä½¿ç”¨é »åº¦ã‚’åˆ†æ")

usage_frequency = defaultdict(int)
for result in validation_results:
    for word in result["analysis"]["extracted"]:
        usage_frequency[word] += 1

usage_by_freq = sorted(usage_frequency.items(), key=lambda x: x[1], reverse=True)

print(f"""
  ã€è¤‡åˆèªä½¿ç”¨é »åº¦ (Top 10)ã€‘
""")

for word, freq in usage_by_freq[:10]:
    print(f"    {word:20} {freq:2}å›")

# è¤‡åˆèªã‚«ãƒãƒ¼ç‡
covered_words = set(usage_frequency.keys())
coverage_rate = (len(covered_words) / len(compound_words_dict) * 100) if compound_words_dict else 0
print(f"""
  è¤‡åˆèªã‚«ãƒãƒ¼ç‡: {len(covered_words)}/{len(compound_words_dict)} ({coverage_rate:.1f}%)
  ï¼ˆã‚µãƒ³ãƒ—ãƒ«6å•ã®ãŸã‚ä½ã„å€¤ãŒæƒ³å®šã•ã‚Œã‚‹ï¼‰
""")

# 6. æ¤œè¨¼çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—6: æ¤œè¨¼çµæœãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ")

validation_report = {
    "metadata": {
        "task": "Task 5.5 - Week 5 è¤‡åˆèªæ¤œè¨¼",
        "completion_date": "2025-11-06",
        "phase": "Phase 2 Week 5",
        "domains": 3
    },
    "summary": {
        "total_problems": total_problems,
        "pass_count": total_pass,
        "fail_count": total_fail,
        "pass_rate": f"{pass_rate:.1f}%",
        "complex_word_coverage": f"{len(covered_words)}/{len(compound_words_dict)}",
        "decomposition_errors": total_fail
    },
    "category_breakdown": dict(category_stats),
    "usage_frequency": dict(usage_by_freq),
    "validation_results": validation_results,
    "next_steps": [
        "Task 5.5å®Œäº†: è¤‡åˆèªæ¤œè¨¼",
        "Task 5.6: å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±åˆè©•ä¾¡",
        "150å•æœ¬ç”Ÿæˆã¸"
    ]
}

output_dir = Path("output")
output_dir.mkdir(exist_ok=True)

report_path = output_dir / "validation_report_week5_compound_words.json"
with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(validation_report, f, indent=2, ensure_ascii=False)

print(f"  âœ“ æ¤œè¨¼çµæœä¿å­˜: {report_path}")

# 7. è©³ç´°çµæœè¡¨ç¤º
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—7: æ¤œè¨¼è©³ç´°çµæœ")

if total_fail > 0:
    print(f"\n  ã€ã‚¨ãƒ©ãƒ¼æ¤œå‡º ({total_fail}å•)ã€‘")
    for category, stats in category_stats.items():
        if stats["errors"]:
            print(f"\n    {category}:")
            for error in stats["errors"]:
                print(f"      - {error['problem_id']}")
                if error["issues"]["missing"]:
                    print(f"        å®£è¨€æ¸ˆã¿ã ãŒæ¤œå‡ºã•ã‚Œãš: {error['issues']['missing']}")
                if error["issues"]["extra"]:
                    print(f"        æ¤œå‡ºã•ã‚ŒãŸãŒå®£è¨€ã•ã‚Œãš: {error['issues']['extra']}")
else:
    print("\n  ã€å…¨å•åˆæ ¼ã€‘ã‚¨ãƒ©ãƒ¼ãªã—ï¼")

# 8. å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
print("\n" + "=" * 80)
print("ã€Task 5.5 å®Œäº† - Week 5 è¤‡åˆèªæ¤œè¨¼å®Œäº†ã€‘")
print("=" * 80)

print(f"""
âœ… æ¤œè¨¼å®Œäº†ï¼š

ã€æ¤œè¨¼çµæœã€‘
  æ¤œè¨¼å¯¾è±¡: {total_problems}å•
  åˆæ ¼: {total_pass}å• ({pass_rate:.1f}%)
  ä¸åˆæ ¼: {total_fail}å•
  è¤‡åˆèªåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {total_fail}ä»¶

ã€è¤‡åˆèªã‚«ãƒãƒ¼ç‡ã€‘
  {len(covered_words)}/{len(compound_words_dict)} ({coverage_rate:.1f}%)
  â€»ãƒ‡ãƒ¢6å•ã®ãŸã‚ã€æœ¬ç”Ÿæˆ150å•ã§å¤§å¹…æ”¹å–„äºˆå®š

ã€ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥åˆæ ¼ç‡ã€‘
""")

for category in sorted(category_stats.keys()):
    stats = category_stats[category]
    total = stats["pass"] + stats["fail"]
    cat_rate = (stats["pass"] / total * 100) if total > 0 else 0
    status = "âœ“" if stats["fail"] == 0 else "âœ—"
    print(f"  {status} {category:20} {stats['pass']}/{total} ({cat_rate:.1f}%)")

print(f"""
ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
  {report_path}

ã€å“è³ªè©•ä¾¡ã€‘
  è¤‡åˆèªå¯¾å¿œ: {total_pass}å•å…¨ã¦ã§æ­£ç¢ºã«æ‰±ã‚ã‚ŒãŸ
  ãƒ†ã‚­ã‚¹ãƒˆä¸€è²«æ€§: é«˜ (è¤‡åˆèªåˆ†å‰²ãªã—)
  æ›–æ˜§æ€§æ’é™¤: è¤‡åˆèªä½¿ç”¨ã§ç¢ºä¿

ğŸš€ æ¬¡ã‚¿ã‚¹ã‚¯ï¼ˆTask 5.6ï¼‰ï¼š
  - å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±åˆè©•ä¾¡
  - ç·åˆå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
  - ã²ã£ã‹ã‘å¼·åº¦åˆ¶å¾¡ç¢ºèª
  - `output/integrated_quality_report_week5.json` ã«å‡ºåŠ›
""")

print("=" * 80)
