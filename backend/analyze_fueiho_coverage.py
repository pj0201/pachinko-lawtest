#!/usr/bin/env python3
"""
é¢¨å–¶æ³•ãƒ»é¢¨å–¶æ³•æ–½è¡Œè¦å‰‡ã®å†…å®¹ã§ã€246å•ã§ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„é …ç›®ã‚’åˆ†æ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ï¼š
1. é¢¨å–¶æ³•ã¨æ–½è¡Œè¦å‰‡ã®å…¨æ¡æ–‡ã‚’æŠ½å‡º
2. 246å•ã®å•é¡Œã®æ ¹æ‹ (basis)ã¨ç…§ã‚‰ã—åˆã‚ã›
3. ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„æ¡æ–‡ã¨å…·ä½“çš„ãªè¨˜è¿°ã‚’å ±å‘Š
"""

import json
import re
from collections import defaultdict

class FueihoGapAnalyzer:
    def __init__(self):
        self.fueiho_articles = {}
        self.enforcement_articles = {}
        self.problems = []
        self.covered_articles = set()
        self.uncovered_fueiho = []
        self.uncovered_enforcement = []

    def load_fueiho_data(self):
        """é¢¨å–¶æ³•ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        print("ğŸ“– é¢¨å–¶æ³•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        try:
            with open('rag_data/hybrid_index.json', 'r', encoding='utf-8') as f:
                data = json.load(f)

            chunks = data.get('metadata_index', {}).get('by_chunk_id', {})

            for chunk_id, chunk_data in chunks.items():
                article_number = chunk_data.get('article_number', '')
                content = chunk_data.get('content', '')

                if 'é¢¨å–¶æ³•' in article_number:
                    # æ¡æ–‡ã‚’æŠ½å‡º
                    articles = self.extract_articles_from_content(content, 'é¢¨å–¶æ³•')
                    for art_num, art_content in articles:
                        if art_num not in self.fueiho_articles:
                            self.fueiho_articles[art_num] = art_content
                        else:
                            # æ—¢å­˜ã®å†…å®¹ã«è¿½åŠ 
                            self.fueiho_articles[art_num] += '\n' + art_content

            print(f"âœ… é¢¨å–¶æ³•æ¡æ–‡ã‚’ {len(self.fueiho_articles)} ä»¶æŠ½å‡º")

        except Exception as e:
            print(f"âš ï¸  é¢¨å–¶æ³•ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def extract_articles_from_content(self, content, law_type):
        """æ¡æ–‡ã‚’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æŠ½å‡º"""
        articles = []

        # ç¬¬Xæ¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern = r'ç¬¬(\d+)æ¡(?:ã®(\d+))?'
        matches = re.finditer(pattern, content)

        article_positions = []
        for match in matches:
            art_num = match.group(1)
            sub_num = match.group(2) if match.group(2) else None
            if sub_num:
                full_art_num = f"ç¬¬{art_num}æ¡ã®{sub_num}"
            else:
                full_art_num = f"ç¬¬{art_num}æ¡"

            article_positions.append({
                'article': full_art_num,
                'pos': match.start(),
                'end': match.end()
            })

        # å„æ¡æ–‡ã®å†…å®¹ã‚’æŠ½å‡º
        for i, art_data in enumerate(article_positions):
            start_pos = art_data['end']
            end_pos = article_positions[i + 1]['pos'] if i + 1 < len(article_positions) else len(content)

            # æ¡æ–‡ã®å†…å®¹ï¼ˆæœ€å¤§500æ–‡å­—ï¼‰
            art_content = content[start_pos:end_pos].strip()
            if len(art_content) > 500:
                art_content = art_content[:500] + '...'

            articles.append((f"{law_type}_{art_data['article']}", art_content))

        return articles

    def load_problems(self):
        """246å•ã®å•é¡Œã‚’èª­ã¿è¾¼ã‚€"""
        print("\nğŸ“– 246å•ã®å•é¡Œã‚’èª­ã¿è¾¼ã¿ä¸­...")

        with open('backend/db/problems.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.problems = data.get('problems', [])

        print(f"âœ… {len(self.problems)} å•ã‚’èª­ã¿è¾¼ã¿")

    def analyze_covered_articles(self):
        """å•é¡Œã§ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¡æ–‡ã‚’åˆ†æ"""
        print("\nğŸ” å•é¡Œã§ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¡æ–‡ã‚’åˆ†æä¸­...")

        # é¢¨å–¶æ³•ã®æ¡æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        fueiho_patterns = [
            r'é¢¨å–¶æ³•\s*ç¬¬(\d+)æ¡(?:ã®(\d+))?',
            r'æ³•\s*ç¬¬(\d+)æ¡(?:ã®(\d+))?',
        ]

        # æ–½è¡Œè¦å‰‡ã®æ¡æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³
        enforcement_patterns = [
            r'æ–½è¡Œè¦å‰‡\s*ç¬¬(\d+)æ¡(?:ã®(\d+))?',
            r'è¦å‰‡\s*ç¬¬(\d+)æ¡(?:ã®(\d+))?',
        ]

        for problem in self.problems:
            basis = problem.get('basis', '')

            # é¢¨å–¶æ³•ã®æ¡æ–‡ã‚’æ¤œå‡º
            for pattern in fueiho_patterns:
                matches = re.finditer(pattern, basis)
                for match in matches:
                    art_num = match.group(1)
                    sub_num = match.group(2) if match.group(2) else None
                    if sub_num:
                        full_art = f"é¢¨å–¶æ³•_ç¬¬{art_num}æ¡ã®{sub_num}"
                    else:
                        full_art = f"é¢¨å–¶æ³•_ç¬¬{art_num}æ¡"
                    self.covered_articles.add(full_art)

            # æ–½è¡Œè¦å‰‡ã®æ¡æ–‡ã‚’æ¤œå‡º
            for pattern in enforcement_patterns:
                matches = re.finditer(pattern, basis)
                for match in matches:
                    art_num = match.group(1)
                    sub_num = match.group(2) if match.group(2) else None
                    if sub_num:
                        full_art = f"æ–½è¡Œè¦å‰‡_ç¬¬{art_num}æ¡ã®{sub_num}"
                    else:
                        full_art = f"æ–½è¡Œè¦å‰‡_ç¬¬{art_num}æ¡"
                    self.covered_articles.add(full_art)

        print(f"âœ… ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¡æ–‡: {len(self.covered_articles)} ä»¶")

    def find_uncovered_articles(self):
        """ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„æ¡æ–‡ã‚’è¦‹ã¤ã‘ã‚‹"""
        print("\nğŸ” ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„æ¡æ–‡ã‚’æ¤œç´¢ä¸­...")

        # é¢¨å–¶æ³•ã®æœªã‚«ãƒãƒ¼æ¡æ–‡
        for article, content in self.fueiho_articles.items():
            if article not in self.covered_articles:
                self.uncovered_fueiho.append({
                    'article': article,
                    'content': content
                })

        print(f"âŒ é¢¨å–¶æ³•ã®æœªã‚«ãƒãƒ¼æ¡æ–‡: {len(self.uncovered_fueiho)} ä»¶")
        print(f"âš ï¸  æ–½è¡Œè¦å‰‡ã®OCRãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    def generate_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("\nğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")

        report_lines = []
        report_lines.append("# é¢¨å–¶æ³•ãƒ»é¢¨å–¶æ³•æ–½è¡Œè¦å‰‡ã®æœªã‚«ãƒãƒ¼é …ç›®åˆ†æ")
        report_lines.append("")
        report_lines.append(f"**åˆ†ææ—¥æ™‚**: {self.get_timestamp()}")
        report_lines.append(f"**å¯¾è±¡å•é¡Œæ•°**: {len(self.problems)} å•")
        report_lines.append("")

        # ã‚µãƒãƒªãƒ¼
        report_lines.append("## ğŸ“Š ã‚µãƒãƒªãƒ¼")
        report_lines.append("")
        report_lines.append(f"- **é¢¨å–¶æ³•æ¡æ–‡ç·æ•°**: {len(self.fueiho_articles)} ä»¶")
        report_lines.append(f"- **ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¡æ–‡**: {len(self.covered_articles)} ä»¶")
        report_lines.append(f"- **æœªã‚«ãƒãƒ¼ã®é¢¨å–¶æ³•æ¡æ–‡**: {len(self.uncovered_fueiho)} ä»¶")
        report_lines.append("")

        # é¢¨å–¶æ³•ã®æœªã‚«ãƒãƒ¼æ¡æ–‡
        if self.uncovered_fueiho:
            report_lines.append("## âŒ é¢¨å–¶æ³•ã§æœªã‚«ãƒãƒ¼ã®æ¡æ–‡")
            report_lines.append("")

            # æ¡æ–‡ç•ªå·ã§ã‚½ãƒ¼ãƒˆ
            sorted_uncovered = sorted(
                self.uncovered_fueiho,
                key=lambda x: self.extract_article_number(x['article'])
            )

            for item in sorted_uncovered:
                article = item['article'].replace('é¢¨å–¶æ³•_', '')
                content = item['content']

                # å†…å®¹ã‚’æ•´å½¢ï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰
                if len(content) > 200:
                    display_content = content[:200] + '...'
                else:
                    display_content = content

                report_lines.append(f"### {article}")
                report_lines.append("")
                report_lines.append("```")
                report_lines.append(display_content)
                report_lines.append("```")
                report_lines.append("")

        # æ–½è¡Œè¦å‰‡ã«ã¤ã„ã¦
        report_lines.append("## âš ï¸  æ–½è¡Œè¦å‰‡ã«ã¤ã„ã¦")
        report_lines.append("")
        report_lines.append("æ–½è¡Œè¦å‰‡ã®OCRãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        report_lines.append("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ãŒã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼š")
        report_lines.append("- `backend/static/pdfs/é¢¨ä¿—å–¶æ¥­ç­‰ã®è¦åˆ¶åŠã³æ¥­å‹™ã®é©æ­£åŒ–ç­‰ã«é–¢ã™ã‚‹æ³•å¾‹æ–½è¡Œè¦å‰‡.pdf`")
        report_lines.append("")
        report_lines.append("æ–½è¡Œè¦å‰‡ã®åˆ†æã‚’è¡Œã†ã«ã¯ã€ã“ã®PDFã‚’OCRå‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        report_lines.append("")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        report_path = 'backend/data/fueiho_coverage_gap.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")

        return '\n'.join(report_lines)

    def extract_article_number(self, article_str):
        """æ¡æ–‡ç•ªå·ã‚’æ•°å€¤ã¨ã—ã¦æŠ½å‡ºï¼ˆã‚½ãƒ¼ãƒˆç”¨ï¼‰"""
        match = re.search(r'ç¬¬(\d+)æ¡', article_str)
        if match:
            return int(match.group(1))
        return 0

    def get_timestamp(self):
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def run(self):
        """åˆ†æã‚’å®Ÿè¡Œ"""
        print("=" * 60)
        print("é¢¨å–¶æ³•ãƒ»é¢¨å–¶æ³•æ–½è¡Œè¦å‰‡ã®æœªã‚«ãƒãƒ¼é …ç›®åˆ†æ")
        print("=" * 60)

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.load_fueiho_data()
        self.load_problems()

        # åˆ†æ
        self.analyze_covered_articles()
        self.find_uncovered_articles()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_report()

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"é¢¨å–¶æ³•æ¡æ–‡ç·æ•°: {len(self.fueiho_articles)} ä»¶")
        print(f"ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹æ¡æ–‡: {len(self.covered_articles)} ä»¶")
        print(f"æœªã‚«ãƒãƒ¼ã®é¢¨å–¶æ³•æ¡æ–‡: {len(self.uncovered_fueiho)} ä»¶")
        print()

        # æœªã‚«ãƒãƒ¼æ¡æ–‡ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        if self.uncovered_fueiho:
            print("æœªã‚«ãƒãƒ¼æ¡æ–‡ã®ä¾‹:")
            for item in self.uncovered_fueiho[:5]:
                article = item['article'].replace('é¢¨å–¶æ³•_', '')
                print(f"  - {article}")
            if len(self.uncovered_fueiho) > 5:
                print(f"  ... ä»– {len(self.uncovered_fueiho) - 5} ä»¶")

        return report

if __name__ == "__main__":
    analyzer = FueihoGapAnalyzer()
    analyzer.run()
