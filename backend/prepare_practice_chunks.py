#!/usr/bin/env python3
"""
Task 4.1: å®Ÿå‹™åˆ†é‡ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è¬›ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³41ãƒ†ãƒ¼ãƒã‹ã‚‰å®Ÿå‹™åˆ†é‡ã‚’æŠ½å‡ºã—ã€
å•é¡Œç”Ÿæˆç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™ã™ã‚‹
"""

import json
import os
from pathlib import Path
from collections import defaultdict

print("=" * 80)
print("ã€Task 4.1: å®Ÿå‹™åˆ†é‡ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘")
print("=" * 80)

# 1. è¬›ç¿’ãƒ†ãƒ¼ãƒã®ç¢ºèª
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—1: è¬›ç¿’ãƒ†ãƒ¼ãƒã®ç¢ºèª")

lecture_dir = Path("rag_data/lecture_text")
if lecture_dir.exists():
    lecture_files = sorted(lecture_dir.glob("*.txt"))
    print(f"  è¦‹ã¤ã‘ãŸãƒ†ãƒ¼ãƒ: {len(lecture_files)}å€‹")
    for f in lecture_files[:5]:
        print(f"    - {f.name}")
    if len(lecture_files) > 5:
        print(f"    ... ä»– {len(lecture_files) - 5}å€‹")
else:
    print(f"âŒ {lecture_dir} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    lecture_files = []

# 2. å®Ÿå‹™åˆ†é‡ãƒ†ãƒ¼ãƒã®åˆ†é¡
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—2: å®Ÿå‹™åˆ†é‡ãƒ†ãƒ¼ãƒã‚’åˆ†é¡")

# å®Ÿå‹™åˆ†é‡ã«è©²å½“ã™ã‚‹ãƒ†ãƒ¼ãƒã‚’å®šç¾©ï¼ˆè¬›ç¿’ãƒ†ãƒ¼ãƒã‹ã‚‰é¸åˆ¥ï¼‰
practice_themes = {
    "operational_procedures": [
        "theme_030_æ–°å°è¨­ç½®ã®æ‰‹ç¶šã.txt",
        "theme_035_è¨­ç½®æ¸ˆã¿éŠæŠ€æ©Ÿã®äº¤æ›æ‰‹ç¶šã.txt",
        "theme_012_ä¸­å¤éŠæŠ€æ©Ÿã®æµé€šç®¡ç†.txt",
        "theme_011_ä¸­å¤éŠæŠ€æ©Ÿã®å–æ‰±ã„.txt"
    ],
    "administrative_enforcement": [
        "theme_013_å–¶æ¥­åœæ­¢å‘½ä»¤.txt",
        "theme_015_å–¶æ¥­åœæ­¢æœŸé–“ã®è¨ˆç®—.txt",
        "theme_019_å–¶æ¥­è¨±å¯ã®å–æ¶ˆã—è¦ä»¶.txt",
        "theme_020_å–¶æ¥­è¨±å¯ã®å¤±åŠ¹äº‹ç”±.txt",
        "theme_041_é•åæ™‚ã®è¡Œæ”¿å‡¦åˆ†.txt"
    ],
    "compliance_and_prevention": [
        "theme_006_ä¸æ­£æ”¹é€ ã®é˜²æ­¢.txt",
        "theme_008_ä¸æ­£è¡Œç‚ºã®ç½°å‰‡.txt",
        "theme_010_ä¸æ­£é˜²æ­¢å¯¾ç­–è¦ç¶±.txt"
    ],
    "technical_management": [
        "theme_003_ãƒãƒƒãƒ—ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£.txt",
        "theme_023_å‹å¼æ¤œå®šã¨ä¸­å¤æ©Ÿã®é–¢ä¿‚.txt",
        "theme_024_å‹å¼æ¤œå®šã¨è£½é€ è€…ã®è²¬ä»».txt",
        "theme_039_éŠæŠ€æ©Ÿã®è£½é€ ç•ªå·ç®¡ç†.txt",
        "theme_040_éŠæŠ€æ©Ÿå‹å¼æ¤œå®šã¯3å¹´æœ‰åŠ¹.txt"
    ],
    "regulation_standards": [
        "theme_034_æ™¯å“äº¤æ›ã®è¦åˆ¶.txt",
        "theme_036_è³æºæœ‰åŠ¹åˆ©ç”¨ä¿ƒé€²æ³•.txt",
        "theme_005_ãƒªã‚µã‚¤ã‚¯ãƒ«æ¨é€²æ³•ã¨ã®é–¢ä¿‚.txt"
    ]
}

practice_theme_count = sum(len(v) for v in practice_themes.values())
print(f"""
  å®Ÿå‹™åˆ†é‡ãƒ†ãƒ¼ãƒ: {practice_theme_count}å€‹
  ã‚«ãƒ†ã‚´ãƒª:
    - å–¶æ¥­æ‰‹ç¶šã: {len(practice_themes['operational_procedures'])}å€‹
    - è¡Œæ”¿å‡¦åˆ†: {len(practice_themes['administrative_enforcement'])}å€‹
    - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹: {len(practice_themes['compliance_and_prevention'])}å€‹
    - æŠ€è¡“ç®¡ç†: {len(practice_themes['technical_management'])}å€‹
    - è¦åˆ¶åŸºæº–: {len(practice_themes['regulation_standards'])}å€‹
""")

# 3. ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã®å®šç¾©
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã‚’å®šç¾©")

chunking_strategy = {
    "method": "logical_units",
    "target_tokens": 500,
    "delimiter": ["ã€‚\n", "ã€‚", "\n\n"],
    "min_chunk_size": 50,
    "max_chunk_size": 1000,
    "categories": list(practice_themes.keys())
}

print(f"""
  ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æ–¹å¼: {chunking_strategy['method']}
  ç›®æ¨™ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {chunking_strategy['target_tokens']}
  æœ€å°/æœ€å¤§: {chunking_strategy['min_chunk_size']}/{chunking_strategy['max_chunk_size']}
""")

# 4. ãƒ†ãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—4: å®Ÿå‹™åˆ†é‡ãƒ†ãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€")

practice_chunks = []
category_stats = defaultdict(lambda: {"count": 0, "tokens": 0})

for category, theme_files in practice_themes.items():
    print(f"\n  ã€{category}ã€‘")

    for theme_file in theme_files:
        theme_path = lecture_dir / theme_file

        if not theme_path.exists():
            print(f"    âš ï¸  {theme_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            continue

        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        try:
            with open(theme_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            if not content:
                print(f"    âš ï¸  {theme_file} ãŒç©ºã§ã™")
                continue

            # ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆæ—¥æœ¬èªã¯3å­—=1ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ï¼‰
            token_count = len(content) // 3

            # ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
            chunk = {
                "chunk_id": f"practice_{category}_{len(practice_chunks):03d}",
                "category": category,
                "source_file": theme_file,
                "content": content,
                "token_count": token_count,
                "source": "lecture_materials"
            }

            practice_chunks.append(chunk)
            category_stats[category]["count"] += 1
            category_stats[category]["tokens"] += token_count

            print(f"    âœ“ {theme_file:40} ({token_count:4}ãƒˆãƒ¼ã‚¯ãƒ³)")

        except Exception as e:
            print(f"    âœ— ã‚¨ãƒ©ãƒ¼: {theme_file} - {e}")

# 5. çµ±è¨ˆæƒ…å ±
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—5: çµ±è¨ˆé›†è¨ˆ")

total_chunks = len(practice_chunks)
total_tokens = sum(s["tokens"] for s in category_stats.values())

print(f"""
  ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}å€‹
  ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {total_tokens}ãƒˆãƒ¼ã‚¯ãƒ³

  ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã€‘
""")

for category, stats in category_stats.items():
    tokens = stats["tokens"]
    percentage = (tokens / total_tokens * 100) if total_tokens > 0 else 0
    print(f"    {category:30} {stats['count']:2}å€‹ ({tokens:5}ãƒˆãƒ¼ã‚¯ãƒ³, {percentage:5.1f}%)")

# 6. å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã®å®šç¾©
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—6: å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©")

output_schema = {
    "metadata": {
        "task": "Task 4.1 - å®Ÿå‹™åˆ†é‡ãƒ‡ãƒ¼ã‚¿æº–å‚™",
        "domain": "practice",
        "total_chunks": total_chunks,
        "total_tokens": total_tokens,
        "chunking_method": "logical_units",
        "source": "lecture_materials (41 themes)"
    },
    "chunking_strategy": chunking_strategy,
    "category_distribution": dict(category_stats),
    "sample_chunks": practice_chunks[:3]  # æœ€åˆã®3å€‹ã‚’ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦å«ã‚ã‚‹
}

print(f"""
  å‡ºåŠ›å½¢å¼: JSONL (1è¡Œ1ãƒãƒ£ãƒ³ã‚¯) + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSON

  å„ãƒãƒ£ãƒ³ã‚¯ã®æ§‹é€ :
  {{
    "chunk_id": "unique_id",
    "category": "category_name",
    "source_file": "theme_XXX_...txt",
    "content": "...",
    "token_count": 500,
    "source": "lecture_materials"
  }}
""")

# 7. å®Ÿå‹™åˆ†é‡ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—7: ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")

output_dir = Path("data")
output_dir.mkdir(exist_ok=True)

# JSONLå½¢å¼ã§ä¿å­˜ï¼ˆ1è¡Œ1ãƒãƒ£ãƒ³ã‚¯ï¼‰
jsonl_path = output_dir / "practice_domain_chunks_prepared.jsonl"
with open(jsonl_path, 'w', encoding='utf-8') as f:
    for chunk in practice_chunks:
        f.write(json.dumps(chunk, ensure_ascii=False) + "\n")

print(f"  âœ“ JSONLä¿å­˜: {jsonl_path} ({total_chunks}è¡Œ)")

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONã‚’ä¿å­˜
metadata_path = output_dir / "practice_domain_chunks_metadata.json"
with open(metadata_path, 'w', encoding='utf-8') as f:
    json.dump(output_schema, f, indent=2, ensure_ascii=False)

print(f"  âœ“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")

# 8. ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
print("\nâœ… ã‚¹ãƒ†ãƒƒãƒ—8: ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ³ã‚¯è¡¨ç¤º")

if practice_chunks:
    for i, chunk in enumerate(practice_chunks[:2], 1):
        print(f"\n  ã€ã‚µãƒ³ãƒ—ãƒ« {i}: {chunk['chunk_id']}ã€‘")
        print(f"    ã‚«ãƒ†ã‚´ãƒª: {chunk['category']}")
        print(f"    ã‚½ãƒ¼ã‚¹: {chunk['source_file']}")
        print(f"    ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {chunk['token_count']}")
        preview = chunk['content'][:100].replace('\n', ' ')
        print(f"    å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview}...")

# 9. å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
print("\n" + "=" * 80)
print("ã€Task 4.1 å®Œäº† - å®Ÿå‹™åˆ†é‡ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†ã€‘")
print("=" * 80)

print(f"""
âœ… æº–å‚™å®Œäº†ï¼š
  - ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}å€‹
  - ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {total_tokens}ãƒˆãƒ¼ã‚¯ãƒ³
  - å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
    - {jsonl_path}
    - {metadata_path}

ğŸ“Š å®Ÿå‹™åˆ†é‡ã®å†…å®¹ï¼š
  - å–¶æ¥­æ‰‹ç¶šãï¼ˆæ–°å°è¨­ç½®ã€ä¸­å¤æ©Ÿæµé€šç­‰ï¼‰
  - è¡Œæ”¿å‡¦åˆ†ï¼ˆå–¶æ¥­åœæ­¢ã€å–æ¶ˆã—ç­‰ï¼‰
  - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ï¼ˆä¸æ­£é˜²æ­¢ã€ç½°å‰‡ç­‰ï¼‰
  - æŠ€è¡“ç®¡ç†ï¼ˆå‹å¼æ¤œå®šã€è£½é€ ç•ªå·ç­‰ï¼‰
  - è¦åˆ¶åŸºæº–ï¼ˆæ™¯å“è¦åˆ¶ã€ãƒªã‚µã‚¤ã‚¯ãƒ«ç­‰ï¼‰

ğŸš€ æ¬¡ã‚¿ã‚¹ã‚¯ï¼ˆTask 4.2ï¼‰ï¼š
  - Claude APIã‚’ä½¿ç”¨ã—ã¦50å•ç”Ÿæˆ
  - è¤‡åˆèªå¯¾å¿œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
  - `output/practice_domain_50_raw.json` ã«å‡ºåŠ›
""")

print("=" * 80)
