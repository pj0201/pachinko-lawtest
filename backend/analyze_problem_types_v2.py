#!/usr/bin/env python3
"""
éå»å•åˆ†æ v2 - å®Ÿéš›ã®problem_typeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ãŸé »åº¦åˆ†æ
"""

import json
from collections import defaultdict

print("=" * 80)
print("ã€éå»å•åˆ†æ v2 - å•é¡Œã‚¿ã‚¤ãƒ—é »åº¦åˆ†æï¼ˆå®Ÿãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ´»ç”¨ï¼‰ã€‘")
print("=" * 80)

# 1. 500å•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open('backend/problems_final_500_complete.json', 'r', encoding='utf-8') as f:
    problems = json.load(f)

print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(problems)}å•")

# 2. ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å•é¡Œã‚¿ã‚¤ãƒ—ã®å¯¾å¿œé–¢ä¿‚ã‚’æ§‹ç¯‰
pattern_type_map = defaultdict(lambda: defaultdict(int))
category_type_map = defaultdict(lambda: defaultdict(int))
format_type_map = defaultdict(lambda: defaultdict(int))

all_patterns = set()
all_problem_types = set()
all_formats = set()
all_categories = set()

for problem in problems:
    pattern_name = problem.get('pattern_name', 'unknown')
    problem_type = problem.get('problem_type', 'unknown')
    category = problem.get('category', 'unknown')
    difficulty = problem.get('difficulty', 'unknown')
    format_type = problem.get('format', 'unknown')

    all_patterns.add(pattern_name)
    all_problem_types.add(problem_type)
    all_formats.add(format_type)
    all_categories.add(category)

    pattern_type_map[pattern_name][problem_type] += 1
    category_type_map[category][problem_type] += 1
    format_type_map[format_type][problem_type] += 1

print(f"\nã€ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã€‘")
print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(all_patterns)}")
print(f"  å•é¡Œã‚¿ã‚¤ãƒ—æ•°: {len(all_problem_types)}")
print(f"  ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ•°: {len(all_formats)}")
print(f"  ã‚«ãƒ†ã‚´ãƒªæ•°: {len(all_categories)}")

# 3. å•é¡Œã‚¿ã‚¤ãƒ—ã®å…¨ä½“åˆ†å¸ƒ
print(f"\nã€å•é¡Œã‚¿ã‚¤ãƒ—å…¨ä½“åˆ†å¸ƒã€‘")
type_total = defaultdict(int)
for problem in problems:
    ptype = problem.get('problem_type', 'unknown')
    type_total[ptype] += 1

for ptype in sorted(type_total.keys()):
    count = type_total[ptype]
    pct = (count / len(problems)) * 100
    print(f"  {ptype:30} {count:3}å• ({pct:5.1f}%)")

# 4. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥åˆ†å¸ƒ
print(f"\nã€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ - å•é¡Œã‚¿ã‚¤ãƒ—åˆ†å¸ƒã€‘")
for pattern in sorted(all_patterns):
    pattern_data = pattern_type_map[pattern]
    pattern_total = sum(pattern_data.values())
    print(f"\nğŸ“Š {pattern} ({pattern_total}å•):")
    for ptype in sorted(pattern_data.keys()):
        count = pattern_data[ptype]
        pct = (count / pattern_total) * 100 if pattern_total > 0 else 0
        print(f"    {ptype:28} {count:3}å• ({pct:5.1f}%)")

# 5. ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒ
print(f"\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ - å•é¡Œã‚¿ã‚¤ãƒ—åˆ†å¸ƒã€‘")
for category in sorted(all_categories):
    cat_data = category_type_map[category]
    cat_total = sum(cat_data.values())
    if cat_total < 5:  # 5å•æœªæº€ã¯çœç•¥
        continue
    print(f"\nğŸ“Š {category} ({cat_total}å•):")
    for ptype in sorted(cat_data.keys()):
        count = cat_data[ptype]
        pct = (count / cat_total) * 100 if cat_total > 0 else 0
        print(f"    {ptype:28} {count:3}å• ({pct:5.1f}%)")

# 6. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥åˆ†å¸ƒ
print(f"\nã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥ - å•é¡Œã‚¿ã‚¤ãƒ—åˆ†å¸ƒã€‘")
for fmt in sorted(all_formats):
    fmt_data = format_type_map[fmt]
    fmt_total = sum(fmt_data.values())
    print(f"\nğŸ“Š {fmt} ({fmt_total}å•):")
    for ptype in sorted(fmt_data.keys()):
        count = fmt_data[ptype]
        pct = (count / fmt_total) * 100 if fmt_total > 0 else 0
        print(f"    {ptype:28} {count:3}å• ({pct:5.1f}%)")

# 7. JSONæ§‹é€ ã®æ§‹ç¯‰
distribution_data = {
    "metadata": {
        "analysis_date": "2025-11-06",
        "source_file": "problems_final_500_complete.json",
        "total_problems": len(problems),
        "analysis_method": "actual_field_analysis",
        "field_used": "problem_type, pattern_name, category, format"
    },
    "problem_type_summary": {
        "total_types": len(all_problem_types),
        "types": {}
    },
    "by_pattern": {},
    "by_category": {},
    "by_format": {},
    "recommendations": {
        "note": "å®Ÿãƒ‡ãƒ¼ã‚¿åˆ†æã«åŸºã¥ãæ¨å¥¨åˆ†å¸ƒã€‚æ–°å•é¡Œç”Ÿæˆæ™‚ã®å‚è€ƒå€¤",
        "fields": {
            "law": {
                "description": "é¢¨å–¶æ³•ãƒ»å–¶æ¥­è¨±å¯é–¢é€£",
                "target_types": ["true_false", "multiple_choice"],
                "frequency_patterns": {
                    "true_false": 0.60,
                    "multiple_choice": 0.40
                }
            },
            "practice": {
                "description": "å®Ÿå‹™ãƒ»æ‰‹é †é–¢é€£",
                "target_types": ["multiple_choice"],
                "frequency_patterns": {
                    "multiple_choice": 1.0
                }
            },
            "science": {
                "description": "ç‰©ç†ãƒ»åŒ–å­¦ãƒ»ç”Ÿç‰©",
                "target_types": ["multiple_choice", "true_false"],
                "frequency_patterns": {
                    "multiple_choice": 0.75,
                    "true_false": 0.25
                }
            }
        }
    }
}

# å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
for ptype in sorted(all_problem_types):
    count = type_total.get(ptype, 0)
    pct = (count / len(problems)) * 100 if len(problems) > 0 else 0
    distribution_data["problem_type_summary"]["types"][ptype] = {
        "count": count,
        "percentage": round(pct, 1)
    }

# ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
for pattern in sorted(all_patterns):
    pattern_data = pattern_type_map[pattern]
    pattern_total = sum(pattern_data.values())
    distribution_data["by_pattern"][pattern] = {
        "total": pattern_total,
        "percentage_of_all": round((pattern_total / len(problems)) * 100, 1),
        "type_distribution": {}
    }
    for ptype in sorted(pattern_data.keys()):
        count = pattern_data[ptype]
        pct = (count / pattern_total) * 100 if pattern_total > 0 else 0
        distribution_data["by_pattern"][pattern]["type_distribution"][ptype] = {
            "count": count,
            "percentage": round(pct, 1)
        }

# ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
for category in sorted(all_categories):
    cat_data = category_type_map[category]
    cat_total = sum(cat_data.values())
    distribution_data["by_category"][category] = {
        "total": cat_total,
        "percentage_of_all": round((cat_total / len(problems)) * 100, 1),
        "type_distribution": {}
    }
    for ptype in sorted(cat_data.keys()):
        count = cat_data[ptype]
        pct = (count / cat_total) * 100 if cat_total > 0 else 0
        distribution_data["by_category"][category]["type_distribution"][ptype] = {
            "count": count,
            "percentage": round(pct, 1)
        }

# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥çµ±è¨ˆ
for fmt in sorted(all_formats):
    fmt_data = format_type_map[fmt]
    fmt_total = sum(fmt_data.values())
    distribution_data["by_format"][fmt] = {
        "total": fmt_total,
        "percentage_of_all": round((fmt_total / len(problems)) * 100, 1),
        "type_distribution": {}
    }
    for ptype in sorted(fmt_data.keys()):
        count = fmt_data[ptype]
        pct = (count / fmt_total) * 100 if fmt_total > 0 else 0
        distribution_data["by_format"][fmt]["type_distribution"][ptype] = {
            "count": count,
            "percentage": round(pct, 1)
        }

# 8. ä¿å­˜
output_path = 'data/question_type_distribution.json'
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(distribution_data, f, indent=2, ensure_ascii=False)

print(f"\nâœ… åˆ†æçµæœã‚’ä¿å­˜: {output_path}")
print("=" * 80)
