#!/usr/bin/env python3
"""
Worker3: å…¨å•é¡Œã®è‡ªå‹•å“è³ªåˆ†æ
- èª¬æ˜æ–‡ã¨å•é¡Œæ–‡ã®çŸ›ç›¾æ¤œå‡º
- æ›–æ˜§è¡¨ç¾ã®æ¤œå‡º
- æ³•ä»¤å¼•ç”¨ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯
- è§£é‡ˆã®å¤šç¾©æ€§æ¤œå‡º
"""
import json
import re
from collections import defaultdict

def load_problems():
    with open('db/problems.json', 'r', encoding='utf-8') as f:
        return json.load(f)['problems']

def check_explanation_mismatch(problem):
    """èª¬æ˜æ–‡ã¨å•é¡Œæ–‡ã®çŸ›ç›¾ãƒã‚§ãƒƒã‚¯"""
    explanation = problem.get('explanation', '')
    problem_text = problem.get('problem_text', '')
    issues = []
    
    # èª¬æ˜æ–‡ã§å¦å®šã—ã¦ã„ã‚‹è¡¨ç¾ãŒå•é¡Œæ–‡ã«ãªã„
    patterns = [
        r'ã€Œ(.+?)ã€ã¨ã„ã†.*?(èª¤ã‚Š|é–“é•ã„|ä¸æ­£ç¢º)',
        r'ã€Œ(.+?)ã€.*?èª¤è§£',
        r'ã€Œ(.+?)ã€.*?é©åˆ‡ã§ãªã„'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, explanation)
        if match:
            phrase = match.group(1)
            if phrase not in problem_text:
                issues.append(f"èª¬æ˜æ–‡ã§å¦å®šã€Œ{phrase}ã€ãŒå•é¡Œæ–‡ã«å­˜åœ¨ã—ãªã„")
    
    return issues

def check_vague_expressions(problem):
    """æ›–æ˜§ãªè¡¨ç¾ãƒã‚§ãƒƒã‚¯"""
    text = problem.get('problem_text', '')
    vague_patterns = {
        'ä¸€å®šã®': 'å…·ä½“çš„ãªæ•°å€¤ãƒ»æœŸé–“ãŒä¸æ˜',
        'é©åˆ‡ãª': 'ä½•ãŒé©åˆ‡ã‹ã®åŸºæº–ãŒä¸æ˜',
        'æ‰€å®šã®': 'å…·ä½“çš„ãªè¦å®šãŒä¸æ˜',
        'å¿…è¦ãª': 'ä½•ãŒå¿…è¦ã‹ã®æ¡ä»¶ãŒä¸æ˜',
        'ã‚±ãƒ¼ã‚¹ã”ã¨ã«': 'å…·ä½“çš„ãªã‚±ãƒ¼ã‚¹åˆ†é¡ãŒä¸æ˜',
        'çŠ¶æ³ã«å¿œã˜ã¦': 'å…·ä½“çš„ãªçŠ¶æ³å®šç¾©ãŒä¸æ˜'
    }
    
    issues = []
    for pattern, reason in vague_patterns.items():
        if pattern in text:
            issues.append(f"æ›–æ˜§è¡¨ç¾ã€Œ{pattern}ã€: {reason}")
    
    return issues

def check_legal_reference_quality(problem):
    """æ³•ä»¤å¼•ç”¨ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯"""
    legal = problem.get('legal_reference', {})
    detail = legal.get('detail', '')
    issues = []
    
    # æŠ½è±¡çš„ãªè¨˜è¿°ã®ã¿
    weak_phrases = ['éµå®ˆã™ã‚‹å¿…è¦', 'è¦å®šã‚’å®ˆã‚‹', 'å®šã‚ã‚‰ã‚Œã¦ã„ã‚‹', 'é©ç”¨ã•ã‚Œã‚‹']
    if any(phrase in detail for phrase in weak_phrases):
        if not any(x in detail for x in ['æ¡æ–‡', 'é …', 'å·', 'å…·ä½“çš„ã«']):
            issues.append(f"æ³•ä»¤å¼•ç”¨ãŒæŠ½è±¡çš„: {detail[:50]}...")
    
    # æ³•ä»¤å¼•ç”¨ãŒãªã„ï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³å•é¡Œã‚’é™¤ãï¼‰
    if not legal.get('law'):
        issues.append("æ³•ä»¤å¼•ç”¨ãªã—ï¼ˆé¢¨å–¶æ³•å•é¡Œã®å ´åˆã¯è¦ä¿®æ­£ï¼‰")
    
    return issues

def check_ambiguity(problem):
    """è§£é‡ˆã®å¤šç¾©æ€§ãƒã‚§ãƒƒã‚¯"""
    text = problem.get('problem_text', '')
    issues = []
    
    # ä¸»èªä¸æ˜
    if re.search(r'(^|ã€‚)(?!.*?(ã¯|ãŒ|ã«ã¤ã„ã¦))', text):
        # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯: æ–‡ã®ä¸»èªãŒä¸æ˜ç¢º
        pass  # ã‚ˆã‚Šè©³ç´°ãªè§£æãŒå¿…è¦
    
    # æŒ‡ç¤ºèªã®å¤šç”¨
    demonstratives = ['ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ', 'å½“è©²', 'æœ¬ä»¶', 'åŒæ³•']
    count = sum(text.count(d) for d in demonstratives)
    if count >= 3:
        issues.append(f"æŒ‡ç¤ºèªå¤šç”¨ï¼ˆ{count}å›ï¼‰: ä½•ã‚’æŒ‡ã™ã‹ä¸æ˜ç¢ºãªå¯èƒ½æ€§")
    
    return issues

def main():
    problems = load_problems()
    print(f"ğŸ” Worker3: å…¨{len(problems)}å•ã®å“è³ªåˆ†æ")
    print("=" * 70)
    
    all_issues = defaultdict(list)
    
    for p in problems:
        pid = p['problem_id']
        
        issues = {
            'èª¬æ˜æ–‡çŸ›ç›¾': check_explanation_mismatch(p),
            'æ›–æ˜§è¡¨ç¾': check_vague_expressions(p),
            'æ³•ä»¤å¼•ç”¨': check_legal_reference_quality(p),
            'å¤šç¾©æ€§': check_ambiguity(p)
        }
        
        for category, issue_list in issues.items():
            if issue_list:
                all_issues[pid].append({
                    'category': category,
                    'issues': issue_list,
                    'problem': p
                })
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š æ¤œå‡ºçµæœã‚µãƒãƒªãƒ¼:")
    print(f"  å•é¡Œã‚ã‚Š: {len(all_issues)}å• / {len(problems)}å• ({len(all_issues)/len(problems)*100:.1f}%)")
    print()
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
    category_counts = defaultdict(int)
    for issues in all_issues.values():
        for issue in issues:
            category_counts[issue['category']] += 1
    
    print("  ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œæ•°:")
    for cat, count in sorted(category_counts.items(), key=lambda x: -x[1]):
        print(f"    - {cat}: {count}ä»¶")
    print()
    
    # ä¸Šä½10å•ã®è©³ç´°è¡¨ç¤º
    print("ğŸ”´ é‡å¤§å•é¡Œï¼ˆä¸Šä½10å•ï¼‰:")
    sorted_issues = sorted(all_issues.items(), key=lambda x: len(x[1]), reverse=True)[:10]
    
    for pid, issues in sorted_issues:
        print(f"\n  ã€å•é¡ŒID {pid}ã€‘")
        p = issues[0]['problem']
        print(f"    å•é¡Œæ–‡: {p['problem_text'][:60]}...")
        
        for issue in issues:
            print(f"    âŒ {issue['category']}:")
            for detail in issue['issues']:
                print(f"       - {detail}")
    
    # JSONå‡ºåŠ›
    output = {
        'total_problems': len(problems),
        'problems_with_issues': len(all_issues),
        'issue_rate': len(all_issues) / len(problems),
        'category_summary': dict(category_counts),
        'detailed_issues': {str(k): v for k, v in all_issues.items()}
    }
    
    with open('review_results_worker3.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… è©³ç´°çµæœã‚’ä¿å­˜: review_results_worker3.json")

if __name__ == '__main__':
    main()
