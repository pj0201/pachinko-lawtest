#!/usr/bin/env python3
"""
OCRå“è³ªæ¤œæŸ»ãƒ¬ãƒãƒ¼ãƒˆ
è½ä¸ãƒ»èª¤å­—ãƒ»èª¤èª­ã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
"""

import json
import re
from pathlib import Path
from collections import defaultdict

OCR_FILE = Path("/home/planj/patshinko-exam-app/data/ocr_results.json")

# ==================== æ—¢çŸ¥ã®èª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ ====================

COMMON_ERRORS = {
    # æ¼¢å­—èª¤èª­ï¼ˆOCRãŒã‚ˆãé–“é•ãˆã‚‹ï¼‰
    'éŠæŠ€æ©Ÿ': [
        'éŠæŠ«æ©Ÿ', 'éŠä¼æ©Ÿ', 'éŠæŠ€è£', 'éŠæŠ€ç¼¶', 'éŠæŠ€è£',
        'åº•æŠ€æ©Ÿ', 'éŠå®Ÿæ©Ÿ', 'ä½œæŠ€æ©Ÿ', 'å™æ©Ÿ', 'éŠæ•·æ©Ÿ'
    ],
    'ç¢ºèª': ['ç¨šèª', 'ç¢ºæ€', 'æ’®èª', 'æ¦·èª'],
    'è¦åˆ¶': ['è¦ªåˆ¶', 'è¢«åˆ¶', 'è¦åˆ¶'],
    'å–¶æ¥­': ['å–¶ç¾½æ¥­', 'å–¶ç¾æ¥­'],
    'æ¥­ç•Œ': ['äº‹è‘‰', 'äº‹æ¥­ç•Œ', 'æ¥­ç¬‘'],
    'éŠæŠ€': ['éŠä¼', 'éŠæŠ«'],
    'é¢¨ä¿—': ['Oé¢¨', '0é¢¨', 'Oé¢¨ä¿—'],
    'ç”³è«‹': ['ç”³è©°', 'ç”³æ¶›'],
}

# ==================== æ¤œæŸ»ã‚¨ãƒ³ã‚¸ãƒ³ ====================

class OCRQualityAnalyzer:
    """OCRå“è³ªåˆ†æ"""

    def __init__(self):
        self.issues = []
        self.stats = {
            'total_pages': 0,
            'total_chars': 0,
            'empty_pages': 0,
            'suspicious_chars': 0,
            'error_patterns': defaultdict(int)
        }

    def analyze(self):
        """å…¨ä½“åˆ†æ"""
        with open(OCR_FILE, 'r', encoding='utf-8') as f:
            results = json.load(f)

        self.stats['total_pages'] = len(results)

        print("=" * 80)
        print("ğŸ” OCRå“è³ªæ¤œæŸ»ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)

        # å„ãƒšãƒ¼ã‚¸ã‚’æ¤œæŸ»
        for i, result in enumerate(results):
            self._check_page(i, result)

        # çµ±è¨ˆè¡¨ç¤º
        self._print_statistics()

        # èª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        self._print_error_patterns(results)

        # è©³ç´°ãƒã‚§ãƒƒã‚¯
        self._detailed_check(results)

    def _check_page(self, page_idx, result):
        """1ãƒšãƒ¼ã‚¸ã‚’æ¤œæŸ»"""
        text = result.get('text', '')
        self.stats['total_chars'] += len(text)

        if len(text) == 0:
            self.stats['empty_pages'] += 1
            self.issues.append({
                'severity': 'HIGH',
                'page': page_idx + 1,
                'issue': 'ç©ºç™½ãƒšãƒ¼ã‚¸ï¼ˆãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—ï¼‰'
            })

    def _print_statistics(self):
        """çµ±è¨ˆæƒ…å ±å‡ºåŠ›"""
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"   ç·ãƒšãƒ¼ã‚¸æ•°: {self.stats['total_pages']}")
        print(f"   ç·æ–‡å­—æ•°: {self.stats['total_chars']:,}å­—")
        print(f"   å¹³å‡æ–‡å­—æ•°: {self.stats['total_chars'] // self.stats['total_pages']}å­—/ãƒšãƒ¼ã‚¸")
        print(f"   ç©ºç™½ãƒšãƒ¼ã‚¸: {self.stats['empty_pages']}")

    def _print_error_patterns(self, results):
        """èª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print(f"\nâš ï¸ æ¤œå‡ºã•ã‚ŒãŸèª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        print("-" * 80)

        error_count = 0

        for correct_word, wrong_patterns in COMMON_ERRORS.items():
            for wrong_word in wrong_patterns:
                page_indices = []

                # å…¨ãƒšãƒ¼ã‚¸ã‹ã‚‰æ¤œç´¢
                for i, result in enumerate(results):
                    text = result.get('text', '')
                    if wrong_word in text:
                        error_count += 1
                        if len(page_indices) < 3:  # æœ€åˆã®3ãƒšãƒ¼ã‚¸ã®ã¿è¨˜éŒ²
                            page_indices.append(i + 1)

                if page_indices:
                    print(f"\nã€{wrong_word}ã€ â†’ ã€{correct_word}ã€ã«ä¿®æ­£æ¨å¥¨")
                    print(f"   æ¤œå‡ºãƒšãƒ¼ã‚¸: {page_indices}")

        if error_count == 0:
            print("   æ¤œå‡ºãªã—ï¼ˆè‰¯å¥½ï¼‰âœ…")

    def _detailed_check(self, results):
        """è©³ç´°ãƒã‚§ãƒƒã‚¯"""
        print(f"\nğŸ” è©³ç´°ãƒã‚§ãƒƒã‚¯çµæœ:")
        print("-" * 80)

        suspicious_count = 0
        issue_categories = defaultdict(int)

        for i, result in enumerate(results):
            text = result.get('text', '')

            # ç–‘ã‚ã—ã„æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            issues = []

            # 1. åˆ†ã‹ã¡æ›¸ããŒãŠã‹ã—ã„
            if re.search(r'[0-9]{2,}', text):  # 2æ¡ä»¥ä¸Šã®æ•°å­—
                if re.search(r'[^\d\s][0-9]{2,}[^\d\s]', text):
                    issues.append('æ•°å­—ã®å‘¨å›²ã«ç©ºç™½ãªã—')

            # 2. å¥ç‚¹ãŒé€£ç¶š
            if 'ã€‚ã€‚' in text or 'ã€ã€' in text:
                issues.append('å¥ç‚¹ãƒ»èª­ç‚¹ãŒé€£ç¶š')

            # 3. ä¸è‡ªç„¶ãªæ”¹è¡Œ
            if text.count('\n') > 10 and len(text) < 500:
                issues.append('æ”¹è¡ŒãŒå¤šã™ãã‚‹')

            # 4. æ˜ã‚‰ã‹ãªè¨˜å·èª¤èª
            if re.search(r'[OO0][^0-9a-zA-Z]', text):  # Oï¼ˆã‚ªãƒ¼ï¼‰ã¨0ï¼ˆã‚¼ãƒ­ï¼‰æ··åŒ
                issues.append('O/0æ··åŒã®å¯èƒ½æ€§')

            if issues:
                for issue in issues:
                    issue_categories[issue] += 1
                    suspicious_count += 1

                if suspicious_count <= 5:  # æœ€åˆã®5ä»¶ã®ã¿è©³ç´°è¡¨ç¤º
                    print(f"\nãƒšãƒ¼ã‚¸ {i+1}:")
                    for issue in issues:
                        print(f"   âš ï¸ {issue}")
                    preview = text[:80].replace('\n', ' ')
                    print(f"   å†…å®¹: {preview}...")

        if suspicious_count == 0:
            print("   ç–‘ã‚ã—ã„å€‹æ‰€: ãªã—ï¼ˆè‰¯å¥½ï¼‰âœ…")
        else:
            print(f"\n   åˆè¨ˆ: {suspicious_count}ãƒšãƒ¼ã‚¸ã§å•é¡Œæ¤œå‡º")

        if issue_categories:
            print(f"\n   å•é¡Œã‚«ãƒ†ã‚´ãƒª:")
            for category, count in issue_categories.items():
                print(f"   - {category}: {count}ä»¶")

    def print_recommendations(self):
        """æ”¹å–„æ¨å¥¨"""
        print(f"\nğŸ’¡ æ”¹å–„æ¨å¥¨:")
        print("-" * 80)
        print("""
1. èª¤å­—ä¿®æ­£: æ¤œå‡ºã•ã‚ŒãŸèª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•ç½®æ›ã§ä¿®æ­£
   ä¾‹) éŠæŠ«æ©Ÿ â†’ éŠæŠ€æ©Ÿ, ç¨šèª â†’ ç¢ºèª

2. å“è³ªå‘ä¸Š: ã‚ˆã‚Šé«˜ã„DPIè¨­å®šã§å†OCRå‡¦ç†ï¼ˆæ¨å¥¨DPI: 200-300ï¼‰

3. æ‰‹å‹•ç¢ºèª: é‡è¦ãªç”¨èªï¼ˆæ³•å¾‹ç”¨èªãªã©ï¼‰ã¯å°‚é–€å®¶ã«ã‚ˆã‚‹ç¢ºèªæ¨å¥¨

4. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰: èª¤å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è“„ç©ã—ã€
   å°†æ¥ã®è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ã«æ´»ç”¨
        """)

# ==================== å®Ÿè¡Œ ====================

if __name__ == '__main__':
    analyzer = OCRQualityAnalyzer()
    analyzer.analyze()
    analyzer.print_recommendations()

    print("\n" + "=" * 80)
    print("âœ… å“è³ªæ¤œæŸ»å®Œäº†")
    print("=" * 80)
