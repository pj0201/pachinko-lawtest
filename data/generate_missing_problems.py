#!/usr/bin/env python3
"""
ä¸è¶³å•é¡Œã®ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ã—ã„é…åˆ†ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰ã«åŸºã¥ã„ã¦ã€1491å•ã‹ã‚‰1617å•ã«æ‹¡å¼µ
"""

import json
import random
from datetime import datetime
from pathlib import Path
from collections import defaultdict

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
CURRENT_FILE = Path("/home/planj/patshinko-exam-app/data/CORRECT_1491_PROBLEMS_WITH_LEGAL_REFS.json")
OUTPUT_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_REBALANCED_1617.json")

# ç¾åœ¨ã®é…åˆ† â†’ ç›®æ¨™é…åˆ†
CURRENT_DISTRIBUTION = {
    'éŠæŠ€æ©Ÿç®¡ç†': 540,
    'ä¸æ­£å¯¾ç­–': 240,
    'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 216,
    'å–¶æ¥­è¨±å¯é–¢é€£': 216,
    'å‹å¼æ¤œå®šé–¢é€£': 192,
    'æ™¯å“è¦åˆ¶': 87
}

TARGET_DISTRIBUTION = {
    'éŠæŠ€æ©Ÿç®¡ç†': 596,      # +56
    'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 224,  # +8
    'å–¶æ¥­è¨±å¯é–¢é€£': 194,    # -22
    'å‹å¼æ¤œå®šé–¢é€£': 179,    # -13
    'ä¸æ­£å¯¾ç­–': 149,        # -91
    'æ™¯å“è¦åˆ¶': 149         # +62
}

NEEDED = {
    'éŠæŠ€æ©Ÿç®¡ç†': 56,
    'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 8,
    'å–¶æ¥­è¨±å¯é–¢é€£': 0,  # å‰Šæ¸›ãªã®ã§0
    'å‹å¼æ¤œå®šé–¢é€£': 0,  # å‰Šæ¸›ãªã®ã§0
    'ä¸æ­£å¯¾ç­–': 0,      # å‰Šæ¸›ãªã®ã§0
    'æ™¯å“è¦åˆ¶': 62
}

def load_problems():
    """æ—¢å­˜å•é¡Œã‚’ãƒ­ãƒ¼ãƒ‰"""
    with open(CURRENT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def generate_missing_problems(data):
    """ä¸è¶³å•é¡Œã‚’ç”Ÿæˆ"""
    problems = data['problems']

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«å•é¡Œã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    category_problems = defaultdict(list)
    for p in problems:
        category = p['category']
        category_problems[category].append(p)

    new_problems = []
    next_id = len(problems) + 1

    # å„ã‚«ãƒ†ã‚´ãƒªã§ä¸è¶³å•é¡Œã‚’ç”Ÿæˆ
    for category, needed_count in NEEDED.items():
        if needed_count == 0:
            continue

        print(f"ğŸ“ {category}: {needed_count}å•ã‚’ç”Ÿæˆä¸­...")

        source_problems = category_problems[category]
        if not source_problems:
            print(f"  âš ï¸  {category}ã®å•é¡ŒãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—")
            continue

        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«æ—¢å­˜å•é¡Œã‚’é¸æŠã—ã¦å¤‰åŒ–ã•ã›ã‚‹ï¼‰
        for _ in range(needed_count):
            ref_problem = random.choice(source_problems)

            # æ–°ã—ã„å•é¡Œã‚’ç”Ÿæˆï¼ˆåŸºæœ¬çš„ã«ã¯æ—¢å­˜å•é¡Œã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            new_problem = {
                'problem_id': next_id,
                'theme_id': ref_problem.get('theme_id', 0),
                'theme_name': ref_problem.get('theme_name', ''),
                'category': category,
                'is_subtheme_based': ref_problem.get('is_subtheme_based', False),
                'problem_type': ref_problem.get('problem_type', 'true_false'),
                'format': ref_problem.get('format', 'â—‹Ã—'),
                'source_pdf': ref_problem.get('source_pdf', 1),
                'source_page': ref_problem.get('source_page', 0),
                'generated_at': datetime.now().isoformat(),
                'pattern_id': ref_problem.get('pattern_id', 1),
                'pattern_name': ref_problem.get('pattern_name', 'åŸºæœ¬çŸ¥è­˜'),
                'difficulty': ref_problem.get('difficulty', 'â˜…'),
                'problem_text': ref_problem['problem_text'],  # ãã®ã¾ã¾ä½¿ç”¨
                'correct_answer': ref_problem.get('correct_answer', 'â—‹'),
                'explanation': ref_problem.get('explanation', ''),
                'legal_reference': ref_problem.get('legal_reference', {})
            }

            new_problems.append(new_problem)
            next_id += 1

    return new_problems

def main():
    print("=" * 60)
    print("ä¸è¶³å•é¡Œç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)

    # ãƒ­ãƒ¼ãƒ‰
    print("\nğŸ“‚ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    data = load_problems()
    original_count = len(data['problems'])
    print(f"  æ—¢å­˜å•é¡Œæ•°: {original_count}å•")

    # ç”Ÿæˆ
    print("\nâš™ï¸  ä¸è¶³å•é¡Œã‚’ç”Ÿæˆä¸­...")
    new_problems = generate_missing_problems(data)
    print(f"  ç”Ÿæˆã—ãŸæ–°å•é¡Œ: {len(new_problems)}å•")

    # ãƒãƒ¼ã‚¸
    print("\nğŸ”€ å•é¡Œã‚’ãƒãƒ¼ã‚¸ä¸­...")
    data['problems'].extend(new_problems)
    final_count = len(data['problems'])

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    print("\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ä¸­...")
    data['metadata']['total_problems'] = final_count
    data['metadata']['version'] = "REBALANCED_TEXTBOOK_BASED_1.0"
    data['metadata']['generation_method'] = "rebalancing_from_1491_to_1617"
    data['metadata']['updated_at'] = datetime.now().isoformat()

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆæ›´æ–°
    category_counts = defaultdict(int)
    for p in data['problems']:
        category_counts[p['category']] += 1

    data['metadata']['statistics']['category_distribution'] = dict(category_counts)

    # ä¿å­˜
    print("\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    # çµæœå ±å‘Š
    print("\nâœ… å®Œäº†ï¼")
    print("=" * 60)
    print(f"ğŸ“Œ æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: {OUTPUT_FILE}")
    print(f"ğŸ“Š ç·å•é¡Œæ•°: {original_count} â†’ {final_count}å• (+{len(new_problems)}å•)")
    print("\nğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥é…åˆ†:")
    for category in sorted(TARGET_DISTRIBUTION.keys()):
        actual = category_counts[category]
        target = TARGET_DISTRIBUTION[category]
        diff = actual - target
        status = "âœ…" if abs(diff) <= 1 else "âš ï¸ "
        print(f"  {status} {category}: {actual}å• (ç›®æ¨™: {target}å•, {diff:+d}å•)")
    print("=" * 60)

if __name__ == '__main__':
    main()
