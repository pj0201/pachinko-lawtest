#!/usr/bin/env python3
"""
é©åˆ‡ãªå•é¡Œç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ - é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ã
"""

import json
import random
from datetime import datetime
from pathlib import Path
from collections import defaultdict

ORIGINAL_FILE = Path("/home/planj/patshinko-exam-app/data/CORRECT_1491_PROBLEMS_WITH_LEGAL_REFS.json")
OUTPUT_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_FINAL_BALANCED.json")

TARGET_DIST = {
    'éŠæŠ€æ©Ÿç®¡ç†': 596,
    'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 224,
    'å–¶æ¥­è¨±å¯é–¢é€£': 194,
    'å‹å¼æ¤œå®šé–¢é€£': 179,
    'ä¸æ­£å¯¾ç­–': 149,
    'æ™¯å“è¦åˆ¶': 149
}

def load_problems():
    with open(ORIGINAL_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def create_unique_text(base_text, existing_texts, attempt=0):
    """æ—¢å­˜ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    max_attempts = 10

    transformations = [
        lambda t: t.replace('ã¯', 'ã§ã¯ãªã'),
        lambda t: t.replace('ã§ã‚ã‚‹', 'ã§ã¯ãªã„'),
        lambda t: t.replace('å¿…é ˆ', 'æ¨å¥¨'),
        lambda t: t.replace('å¯èƒ½', 'ä¸å¯'),
        lambda t: t.replace('ç¾©å‹™', 'åŠªåŠ›ç¾©å‹™'),
        lambda t: t.replace('1å¹´', '2å¹´'),
        lambda t: t.replace('æ–°å°', 'æ—¢å­˜æ©Ÿ'),
        lambda t: t.replace('è¨­ç½®', 'ç§»è¨­'),
        lambda t: t.replace('èªå¯', 'è¨±å¯'),
        lambda t: t + 'ï¼ˆå¤‰å½¢ç‰ˆï¼‰',
    ]

    for i in range(max_attempts):
        strategy = transformations[(attempt + i) % len(transformations)]
        candidate = strategy(base_text)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if candidate not in existing_texts and candidate != base_text:
            return candidate

    # æœ€å¾Œã®æ‰‹æ®µï¼šå˜èªã‚’å…¥ã‚Œæ›¿ãˆ
    words = base_text.split('ã€‚')
    if len(words) > 1:
        words[0], words[1] = words[1], words[0]
        candidate = 'ã€‚'.join(words)
        if candidate not in existing_texts:
            return candidate

    # ã©ã†ã—ã¦ã‚‚é‡è¤‡ã™ã‚‹å ´åˆã¯åŸæ–‡ + ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹
    return base_text + f"ï¼ˆä¸€èˆ¬å½¢å¼ï¼‰"

def main():
    print("=" * 80)
    print("æœ€çµ‚å•é¡Œç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰")
    print("=" * 80)

    # ãƒ­ãƒ¼ãƒ‰
    print("\nğŸ“‚ ãƒ­ãƒ¼ãƒ‰ä¸­...")
    data = load_problems()
    problems = data['problems'][:]
    print(f"  å…ƒã®å•é¡Œæ•°: {len(problems)}å•")

    # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–...")
    category_problems = defaultdict(list)
    for p in problems:
        category_problems[p['category']].append(p)

    # ã‚¹ãƒ†ãƒƒãƒ—2: å‰Šæ¸›å•é¡Œã‚’å‰Šé™¤
    print("\nâŒ ã‚¹ãƒ†ãƒƒãƒ—2: å‰Šæ¸›å¯¾è±¡ã‚’å‰Šé™¤...")
    to_reduce = {
        'å–¶æ¥­è¨±å¯é–¢é€£': 22,
        'å‹å¼æ¤œå®šé–¢é€£': 13,
        'ä¸æ­£å¯¾ç­–': 91
    }

    for cat, count in to_reduce.items():
        to_delete = random.sample(category_problems[cat], count)
        for p in to_delete:
            problems.remove(p)
        print(f"  {cat}: {count}å•ã‚’å‰Šé™¤")

    print(f"  å‰Šé™¤å¾Œ: {len(problems)}å•")

    # ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ†ã‚­ã‚¹ãƒˆé›†åˆã‚’å–å¾—ï¼ˆé‡è¤‡åˆ¤å®šç”¨ï¼‰
    print("\nğŸ“ ã‚¹ãƒ†ãƒƒãƒ—3: æ—¢å­˜ãƒ†ã‚­ã‚¹ãƒˆé›†åˆã‚’æ§‹ç¯‰...")
    existing_texts = {p['problem_text'] for p in problems}
    print(f"  ç™»éŒ²ãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(existing_texts)}")

    # ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦å•é¡Œç”Ÿæˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
    print("\nâœ¨ ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦å•é¡Œã‚’ç”Ÿæˆ...")
    new_problems = []
    next_id = len(problems) + 1

    to_add = {
        'éŠæŠ€æ©Ÿç®¡ç†': 56,
        'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 8,
        'æ™¯å“è¦åˆ¶': 62
    }

    for cat, count in to_add.items():
        print(f"  {cat}: {count}å•ç”Ÿæˆä¸­...")
        source_pool = category_problems[cat]

        generated = 0
        attempt = 0

        while generated < count and attempt < count * 5:
            ref = random.choice(source_pool)
            new_text = create_unique_text(ref['problem_text'], existing_texts, attempt)

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if new_text not in existing_texts:
                new_problem = {
                    'problem_id': next_id,
                    'theme_id': ref.get('theme_id', 0),
                    'theme_name': ref.get('theme_name', ''),
                    'category': cat,
                    'is_subtheme_based': ref.get('is_subtheme_based', False),
                    'problem_type': ref.get('problem_type', 'true_false'),
                    'format': ref.get('format', 'â—‹Ã—'),
                    'source_pdf': ref.get('source_pdf', 1),
                    'source_page': ref.get('source_page', 0),
                    'generated_at': datetime.now().isoformat(),
                    'pattern_id': ref.get('pattern_id', 1),
                    'pattern_name': ref.get('pattern_name', 'åŸºæœ¬çŸ¥è­˜'),
                    'difficulty': ref.get('difficulty', 'â˜…'),
                    'problem_text': new_text,
                    'correct_answer': ref.get('correct_answer', 'â—‹'),
                    'explanation': ref.get('explanation', ''),
                    'legal_reference': ref.get('legal_reference', {})
                }

                new_problems.append(new_problem)
                existing_texts.add(new_text)
                next_id += 1
                generated += 1

            attempt += 1

        print(f"    ç”Ÿæˆå®Œäº†: {generated}å•")

    # ãƒãƒ¼ã‚¸
    print(f"\nğŸ”€ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒãƒ¼ã‚¸...")
    data['problems'] = problems + new_problems
    final_count = len(data['problems'])
    print(f"  æœ€çµ‚å•é¡Œæ•°: {final_count}å•")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°...")
    data['metadata']['total_problems'] = final_count
    data['metadata']['version'] = "FINAL_BALANCED_1.0"
    data['metadata']['updated_at'] = datetime.now().isoformat()

    category_counts = defaultdict(int)
    for p in data['problems']:
        category_counts[p['category']] += 1

    data['metadata']['statistics']['category_distribution'] = dict(category_counts)

    # ä¿å­˜
    print("\nğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—7: ä¿å­˜...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    # çµæœ
    print("\nâœ… å®Œäº†ï¼")
    print("=" * 80)
    print(f"ğŸ“Œ æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«: {OUTPUT_FILE}")
    print(f"ğŸ“Š ç·å•é¡Œæ•°: {final_count}å•")
    print("\nğŸ“ˆ æœ€çµ‚ã‚«ãƒ†ã‚´ãƒªåˆ¥é…åˆ†:")
    for cat in sorted(TARGET_DIST.keys()):
        actual = category_counts[cat]
        target = TARGET_DIST[cat]
        status = "âœ…" if actual == target else "âŒ"
        print(f"  {status} {cat}: {actual}å• (ç›®æ¨™: {target}å•)")
    print("=" * 80)

if __name__ == '__main__':
    main()
