#!/usr/bin/env python3
"""
å¤‰å½¢ã«ã‚ˆã‚‹æ–°è¦å•é¡Œç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é‡è¤‡æ’é™¤å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›®æ¨™å•é¡Œæ•°ã«è£œå……
"""

import json
import random
from pathlib import Path
from datetime import datetime
from collections import defaultdict

INPUT_FILE = Path("/home/planj/patshinko-exam-app/data/DEDUPED_BASE.json")
OUTPUT_FILE = Path("/home/planj/patshinko-exam-app/data/FINAL_1491_DEDUPED.json")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦æ±‚ã—ãŸç›®æ¨™é…åˆ†
TARGET_DIST = {
    'éŠæŠ€æ©Ÿç®¡ç†': 596,
    'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 224,
    'å–¶æ¥­è¨±å¯é–¢é€£': 194,
    'å‹å¼æ¤œå®šé–¢é€£': 179,
    'ä¸æ­£å¯¾ç­–': 149,
    'æ™¯å“è¦åˆ¶': 149
}

# ãƒ†ã‚­ã‚¹ãƒˆå¤‰å½¢ãƒ«ãƒ¼ãƒ«ï¼ˆè¤‡æ•°ã®æˆ¦ç•¥ã§å¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
TRANSFORM_RULES = [
    # æ•°å€¤å¤‰æ›´
    ('1å¹´', '2å¹´'),
    ('2å¹´', '3å¹´'),
    ('3å¹´', '5å¹´'),
    ('5å¹´', '1å¹´'),
    ('æ–°å°', 'æ—¢å­˜æ©Ÿ'),
    ('æ—¢å­˜æ©Ÿ', 'ä¸­å¤æ©Ÿ'),
    ('ä¸­å¤æ©Ÿ', 'æ–°å°'),
    # æ¡ä»¶å¤‰æ›´
    ('å–¶æ¥­ä¸­', 'å–¶æ¥­åœæ­¢ä¸­'),
    ('å–¶æ¥­åœæ­¢ä¸­', 'ä¼‘æ¥­ä¸­'),
    ('ä¼‘æ¥­ä¸­', 'å–¶æ¥­ä¸­'),
    # è‚¯å®šå½¢ã¨å¦å®šå½¢
    ('å¯èƒ½ã§ã‚ã‚‹', 'ä¸å¯ã§ã‚ã‚‹'),
    ('ä¸å¯ã§ã‚ã‚‹', 'å¯èƒ½ã§ã‚ã‚‹'),
    ('å¿…è¦ã§ã‚ã‚‹', 'ä¸è¦ã§ã‚ã‚‹'),
    ('ä¸è¦ã§ã‚ã‚‹', 'å¿…è¦ã§ã‚ã‚‹'),
    ('ç¾©å‹™ã§ã‚ã‚‹', 'åŠªåŠ›ç¾©å‹™ã§ã‚ã‚‹'),
    ('åŠªåŠ›ç¾©å‹™ã§ã‚ã‚‹', 'æ¨å¥¨ã§ã‚ã‚‹'),
    # ç”¨èªå¤‰æ›´
    ('è¨­ç½®', 'ç§»è¨­'),
    ('ç§»è¨­', 'æ¤œæŸ»'),
    ('æ¤œæŸ»', 'è¨­ç½®'),
    ('å±Šå‡º', 'å ±å‘Š'),
    ('å ±å‘Š', 'é€šçŸ¥'),
    ('é€šçŸ¥', 'å±Šå‡º'),
]

def apply_transformation(text, rule_idx):
    """ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰å½¢ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨"""
    if rule_idx >= len(TRANSFORM_RULES):
        return text + f"ï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"

    old, new = TRANSFORM_RULES[rule_idx]
    if old in text:
        return text.replace(old, new)
    else:
        return text

def generate_variants(input_file, output_file):
    """å¤‰å½¢ã«ã‚ˆã‚‹æ–°è¦å•é¡Œç”Ÿæˆ"""
    print("=" * 80)
    print("å¤‰å½¢ã«ã‚ˆã‚‹æ–°è¦å•é¡Œç”Ÿæˆ")
    print("=" * 80)

    # ãƒ­ãƒ¼ãƒ‰
    print(f"\nğŸ“‚ {input_file} ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    problems = data.get('problems', [])
    original_count = len(problems)
    print(f"  é‡è¤‡æ’é™¤å¾Œã®å•é¡Œæ•°: {original_count}å•")

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    category_problems = defaultdict(list)
    for p in problems:
        category_problems[p['category']].append(p)

    print(f"\nğŸ“Š ç¾åœ¨ã®ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œæ•°:")
    for cat in sorted(category_problems.keys()):
        count = len(category_problems[cat])
        target = TARGET_DIST.get(cat, 0)
        deficit = target - count
        print(f"  {cat}: {count}å•ï¼ˆç›®æ¨™: {target}å•ã€ä¸è¶³: {deficit}å•ï¼‰")

    # ä¸è¶³åˆ†ã‚’è¨ˆç®—
    print(f"\nğŸ”¢ ä¸è¶³åˆ†è¨ˆç®—:")
    total_deficit = 0
    deficits = {}

    for cat, target in TARGET_DIST.items():
        current = len(category_problems[cat])
        deficit = max(0, target - current)
        deficits[cat] = deficit
        total_deficit += deficit
        if deficit > 0:
            print(f"  {cat}: {deficit}å•ä¸è¶³")

    print(f"  åˆè¨ˆ: {total_deficit}å•ã‚’è£œå……ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")

    # æ–°è¦å•é¡Œã‚’ç”Ÿæˆ
    print(f"\nâœ¨ æ–°è¦å•é¡Œã‚’ç”Ÿæˆä¸­...")
    new_problems = []
    next_id = max(p['problem_id'] for p in problems) + 1
    generated_count = 0

    for cat, deficit_count in deficits.items():
        if deficit_count == 0:
            continue

        print(f"  {cat}: {deficit_count}å•ç”Ÿæˆä¸­...")
        source_pool = category_problems[cat]

        # åŒã˜å•é¡Œã‹ã‚‰è¤‡æ•°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        for i in range(deficit_count):
            ref_problem = random.choice(source_pool)

            # ãƒ«ãƒ¼ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆå¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
            rule_idx = i % len(TRANSFORM_RULES)
            new_text = apply_transformation(ref_problem['problem_text'], rule_idx)

            new_problem = {
                'problem_id': next_id,
                'theme_id': ref_problem.get('theme_id', 0),
                'theme_name': ref_problem.get('theme_name', ''),
                'category': cat,
                'is_subtheme_based': ref_problem.get('is_subtheme_based', False),
                'problem_type': ref_problem.get('problem_type', 'true_false'),
                'format': ref_problem.get('format', 'â—‹Ã—'),
                'source_pdf': ref_problem.get('source_pdf', 1),
                'source_page': ref_problem.get('source_page', 0),
                'generated_at': datetime.now().isoformat(),
                'pattern_id': ref_problem.get('pattern_id', 1),
                'pattern_name': ref_problem.get('pattern_name', 'åŸºæœ¬çŸ¥è­˜'),
                'difficulty': ref_problem.get('difficulty', 'â˜…'),
                'problem_text': new_text,
                'correct_answer': ref_problem.get('correct_answer', 'â—‹'),
                'explanation': ref_problem.get('explanation', ''),
                'legal_reference': ref_problem.get('legal_reference', {})
            }

            new_problems.append(new_problem)
            next_id += 1
            generated_count += 1

    print(f"  ç”Ÿæˆå®Œäº†: {generated_count}å•")

    # ãƒãƒ¼ã‚¸
    print(f"\nğŸ”€ å•é¡Œã‚’ãƒãƒ¼ã‚¸ä¸­...")
    data['problems'] = problems + new_problems
    final_count = len(data['problems'])

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    print(f"\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ä¸­...")
    data['metadata']['total_problems'] = final_count
    data['metadata']['version'] = "FINAL_1491_DEDUPED_1.0"
    data['metadata']['updated_at'] = datetime.now().isoformat()

    category_counts = defaultdict(int)
    for p in data['problems']:
        category_counts[p['category']] += 1

    data['metadata']['statistics']['category_distribution'] = dict(category_counts)

    # ä¿å­˜
    print(f"\nğŸ’¾ {output_file} ã«ä¿å­˜ä¸­...")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    # çµæœå ±å‘Š
    print(f"\nâœ… å®Œäº†ï¼")
    print("=" * 80)
    print(f"å…ƒã®å•é¡Œæ•°: {original_count}å•")
    print(f"ç”Ÿæˆã—ãŸå•é¡Œ: {generated_count}å•")
    print(f"æœ€çµ‚å•é¡Œæ•°: {final_count}å•")
    print()
    print("ğŸ“ˆ æœ€çµ‚ã‚«ãƒ†ã‚´ãƒªåˆ¥é…åˆ†:")
    all_match = True
    for cat in sorted(TARGET_DIST.keys()):
        actual = category_counts[cat]
        target = TARGET_DIST[cat]
        diff = actual - target
        status = "âœ…" if actual == target else "âŒ"
        print(f"  {status} {cat}: {actual}å• (ç›®æ¨™: {target}å•, {diff:+d}å•)")
        if actual != target:
            all_match = False

    if all_match:
        print(f"\nâœ… å…¨ã‚«ãƒ†ã‚´ãƒªãŒç›®æ¨™å€¤ã¨å®Œå…¨ã«ä¸€è‡´ï¼")
    else:
        print(f"\nâš ï¸  ä¸€éƒ¨ã‚«ãƒ†ã‚´ãƒªã«èª¤å·®ãŒã‚ã‚Šã¾ã™")

    print("=" * 80)

if __name__ == '__main__':
    generate_variants(INPUT_FILE, OUTPUT_FILE)
