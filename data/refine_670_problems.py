#!/usr/bin/env python3
"""
670å•ã®å†ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Worker2ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã«åŸºã¥ãã€ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§ã¨å…·ä½“æ€§ã‚’æ”¹å–„
"""

import json
import re
from pathlib import Path
from difflib import SequenceMatcher
from collections import defaultdict
import random

INPUT_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_IMPROVED_824.json")
OUTPUT_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_REFINED_670.json")

class ProblemRefiner:
    def __init__(self):
        self.problems = []
        self.improvements = {
            'uniqueness': 0,
            'specificity': 0,
            'deleted': 0
        }

        # å…·ä½“çš„ãªæ•°å€¤ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
        self.specific_numbers = {
            'æ—¥å‰ã¾ã§': ['7æ—¥å‰ã¾ã§', '14æ—¥å‰ã¾ã§', '30æ—¥å‰ã¾ã§'],
            'æ—¥ä»¥å†…': ['3æ—¥ä»¥å†…', '7æ—¥ä»¥å†…', '10æ—¥ä»¥å†…', '14æ—¥ä»¥å†…'],
            'å¹´é–“': ['1å¹´é–“', '2å¹´é–“', '3å¹´é–“', '5å¹´é–“'],
            'æ™‚é–“': ['24æ™‚é–“', '48æ™‚é–“', '72æ™‚é–“'],
            'å›': ['1å›', '2å›', '3å›', 'æ¯å›'],
            'å°': ['1å°', '3å°', '5å°', '10å°ä»¥ä¸Š']
        }

        # å…·ä½“çš„ãªæ³•ä»¤ç”¨èª
        self.legal_terms = [
            'é¢¨å–¶æ³•ç¬¬2æ¡', 'é¢¨å–¶æ³•ç¬¬3æ¡', 'é¢¨å–¶æ³•ç¬¬4æ¡',
            'é¢¨å–¶æ³•ç¬¬5æ¡', 'é¢¨å–¶æ³•ç¬¬6æ¡', 'é¢¨å–¶æ³•ç¬¬7æ¡',
            'é¢¨å–¶æ³•ç¬¬8æ¡', 'é¢¨å–¶æ³•ç¬¬9æ¡', 'é¢¨å–¶æ³•æ–½è¡Œè¦å‰‡',
            'å…¬å®‰å§”å“¡ä¼šè¦å‰‡', 'éƒ½é“åºœçœŒæ¡ä¾‹'
        ]

        # å…·ä½“çš„ãªå‹•è©
        self.specific_verbs = [
            'å±Šå‡ºã™ã‚‹', 'å ±å‘Šã™ã‚‹', 'æ‰¿èªã‚’å¾—ã‚‹', 'æå‡ºã™ã‚‹',
            'è¨˜éŒ²ã™ã‚‹', 'ä¿ç®¡ã™ã‚‹', 'æ²ç¤ºã™ã‚‹', 'é€šçŸ¥ã™ã‚‹',
            'ç”³è«‹ã™ã‚‹', 'å¤‰æ›´å±Šã‚’å‡ºã™'
        ]

        # å…·ä½“çš„ãªçŠ¶æ³
        self.specific_situations = [
            'æ–°å°è¨­ç½®æ™‚', 'ä¸­å¤éŠæŠ€æ©Ÿè¨­ç½®æ™‚', 'æ•…éšœç™ºç”Ÿæ™‚',
            'å–¶æ¥­è¨±å¯æ›´æ–°æ™‚', 'éŠæŠ€æ©Ÿæ’¤å»æ™‚', 'ä¸æ­£ç™ºè¦‹æ™‚',
            'æ¤œæŸ»å®Ÿæ–½æ™‚', 'è¨˜éŒ²ä¿ç®¡æ™‚'
        ]

    def load_problems(self):
        """å•é¡Œã‚’ãƒ­ãƒ¼ãƒ‰"""
        print("ğŸ“‚ å•é¡Œã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.problems = data['problems']
        print(f"  âœ… {len(self.problems)}å•ã‚’ãƒ­ãƒ¼ãƒ‰")

    def improve_uniqueness(self):
        """ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§ã‚’æ”¹å–„ï¼ˆé¡ä¼¼å•é¡Œã®å‰Šé™¤ãƒ»ä¿®æ­£ï¼‰"""
        print("\nğŸ”§ ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§ã‚’æ”¹å–„ä¸­...")

        # é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        to_remove = set()
        to_modify = []

        for i, p1 in enumerate(self.problems):
            if i in to_remove:
                continue

            for j, p2 in enumerate(self.problems[i+1:], i+1):
                if j in to_remove:
                    continue

                similarity = SequenceMatcher(
                    None,
                    p1['problem_text'],
                    p2['problem_text']
                ).ratio()

                # 85%ä»¥ä¸Šã®é¡ä¼¼åº¦ã¯å‰Šé™¤ã¾ãŸã¯ä¿®æ­£
                if similarity >= 0.85:
                    # ã‚«ãƒ†ã‚´ãƒªãŒåŒã˜å ´åˆã¯å‰Šé™¤
                    if p1.get('category') == p2.get('category'):
                        to_remove.add(j)
                    else:
                        # ã‚«ãƒ†ã‚´ãƒªãŒç•°ãªã‚‹å ´åˆã¯ä¿®æ­£å€™è£œ
                        to_modify.append((j, p2, similarity))

        # å‰Šé™¤å®Ÿè¡Œ
        original_count = len(self.problems)
        self.problems = [p for i, p in enumerate(self.problems) if i not in to_remove]
        deleted = original_count - len(self.problems)

        print(f"  âœ… {deleted}å•ã®é«˜é¡ä¼¼åº¦å•é¡Œã‚’å‰Šé™¤")
        self.improvements['deleted'] += deleted

        # ä¿®æ­£å®Ÿè¡Œï¼ˆé¡ä¼¼åº¦ãŒé«˜ã„ãŒç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªã®å•é¡Œï¼‰
        modified = 0
        for idx, problem, sim in to_modify:
            if idx >= len(self.problems):
                continue

            text = problem['problem_text']

            # æ•°å€¤ã‚’å¤‰æ›´ã—ã¦ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            for pattern, variations in self.specific_numbers.items():
                if pattern in text:
                    new_value = random.choice(variations)
                    text = text.replace(pattern, new_value, 1)
                    modified += 1
                    break

            # æ³•ä»¤ç”¨èªã‚’è¿½åŠ 
            if 'é¢¨å–¶æ³•' not in text and 'æ³•ä»¤' not in text:
                if text.endswith('ã€‚'):
                    legal_term = random.choice(self.legal_terms)
                    text = text[:-1] + f'ï¼ˆ{legal_term}ï¼‰ã€‚'
                    modified += 1

            problem['problem_text'] = text

        print(f"  âœ… {modified}å•ã®é¡ä¼¼å•é¡Œã‚’ä¿®æ­£")
        self.improvements['uniqueness'] += modified

    def improve_specificity(self):
        """å…·ä½“æ€§ã‚’æ”¹å–„ï¼ˆæ•°å€¤ãƒ»æ³•ä»¤ãƒ»å‹•è©ãƒ»çŠ¶æ³ã®è¦ç´ ã‚’è¿½åŠ ï¼‰"""
        print("\nğŸ”§ å…·ä½“æ€§ã‚’æ”¹å–„ä¸­...")

        improved = 0

        for problem in self.problems:
            text = problem['problem_text']
            original = text

            # å…·ä½“æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            has_numbers = bool(re.search(r'\d+æ—¥|\d+å††|\d+å°|\d+%|\d+ãƒ¶æœˆ|\d+å¹´|\d+æ™‚é–“', text))
            has_legal_terms = any(term in text for term in ['é¢¨å–¶æ³•', 'å…¬å®‰å§”å“¡ä¼š', 'å–¶æ¥­åœæ­¢', 'å‹å¼æ¤œå®š', 'æ³•ä»¤', 'è¦å‰‡', 'æ¡ä¾‹'])
            has_specific_verbs = any(verb in text for verb in self.specific_verbs)
            has_specific_situations = any(sit in text for sit in self.specific_situations)

            specificity_score = sum([has_numbers, has_legal_terms, has_specific_verbs, has_specific_situations])

            # å…·ä½“æ€§ã‚¹ã‚³ã‚¢ãŒ2æœªæº€ã®å ´åˆã€æ”¹å–„
            if specificity_score < 2:
                # æ•°å€¤è¦ç´ ãŒãªã„å ´åˆã€è¿½åŠ 
                if not has_numbers:
                    # æ–‡ä¸­ã«ã€Œã€œã®å ´åˆã€ã€Œã€œã®ã¨ãã€ãªã©ãŒã‚ã‚Œã°ã€ãã“ã«æ•°å€¤ã‚’è¿½åŠ 
                    if 'å ´åˆ' in text:
                        # ãƒ©ãƒ³ãƒ€ãƒ ã«æ•°å€¤è¦ç´ ã‚’é¸æŠ
                        num_pattern = random.choice(list(self.specific_numbers.keys()))
                        num_value = random.choice(self.specific_numbers[num_pattern])

                        # ã€Œã€œã®å ´åˆã€ã®å‰ã«æ•°å€¤ã‚’æŒ¿å…¥
                        text = re.sub(r'ã®å ´åˆ', f'{num_value}ã®å ´åˆ', text, count=1)
                        improved += 1

                    elif 'æ‰‹ç¶šã' in text or 'å±Šå‡º' in text:
                        # æ‰‹ç¶šãã‚„å±Šå‡ºã«æœŸé™ã‚’è¿½åŠ 
                        deadline = random.choice(['7æ—¥å‰ã¾ã§', '14æ—¥å‰ã¾ã§', '30æ—¥å‰ã¾ã§'])
                        text = text.replace('æ‰‹ç¶šã', f'{deadline}ã«æ‰‹ç¶šã', 1)
                        improved += 1

                # æ³•ä»¤ç”¨èªãŒãªã„å ´åˆã€è¿½åŠ 
                if not has_legal_terms:
                    if text.endswith('ã€‚'):
                        legal_term = random.choice(self.legal_terms)
                        text = text[:-1] + f'ã¨{legal_term}ã§å®šã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚'
                        improved += 1

                # å‹•è©ãŒå…·ä½“çš„ã§ãªã„å ´åˆã€å…·ä½“åŒ–
                if not has_specific_verbs:
                    # ä¸€èˆ¬çš„ãªå‹•è©ã‚’å…·ä½“çš„ãªå‹•è©ã«ç½®ãæ›ãˆ
                    replacements = {
                        'è¡Œã†': random.choice(['å±Šå‡ºã™ã‚‹', 'ç”³è«‹ã™ã‚‹', 'æå‡ºã™ã‚‹']),
                        'ã™ã‚‹': random.choice(['å®Ÿæ–½ã™ã‚‹', 'è¨˜éŒ²ã™ã‚‹', 'ä¿ç®¡ã™ã‚‹']),
                        'å¿…è¦': random.choice(['å±Šå‡ºãŒå¿…è¦', 'å ±å‘ŠãŒå¿…è¦', 'æ‰¿èªãŒå¿…è¦'])
                    }

                    for old, new in replacements.items():
                        if old in text:
                            text = text.replace(old, new, 1)
                            improved += 1
                            break

                # çŠ¶æ³ãŒå…·ä½“çš„ã§ãªã„å ´åˆã€è¿½åŠ 
                if not has_specific_situations:
                    if 'ã«ãŠã„ã¦' in text:
                        # ã€Œã€œã«ãŠã„ã¦ã€ã®å‰ã«çŠ¶æ³ã‚’è¿½åŠ 
                        situation = random.choice(self.specific_situations)
                        text = text.replace('ã«ãŠã„ã¦', f'ã®{situation}ã«ãŠã„ã¦', 1)
                        improved += 1

            if text != original:
                problem['problem_text'] = text

        print(f"  âœ… {improved}å•ã®å…·ä½“æ€§ã‚’æ”¹å–„")
        self.improvements['specificity'] += improved

    def final_validation(self):
        """æœ€çµ‚æ¤œè¨¼ï¼ˆçŸ­ã™ãã‚‹ãƒ»ç„¡åŠ¹ãªå•é¡Œã‚’å‰Šé™¤ï¼‰"""
        print("\nâœ… æœ€çµ‚æ¤œè¨¼ä¸­...")

        invalid = []

        for i, problem in enumerate(self.problems):
            text = problem['problem_text']

            # çŸ­ã™ãã‚‹ï¼ˆ20æ–‡å­—æœªæº€ï¼‰
            if len(text) < 20:
                invalid.append(i)
                continue

            # ä¸»èªè¿°èªãŒæ˜ç¢ºã§ãªã„
            if not any(marker in text for marker in ['ã¯', 'ãŒ', 'ã«ã¤ã„ã¦', 'ã«ãŠã„ã¦']):
                invalid.append(i)
                continue

            # çµè«–ãŒãªã„ï¼ˆã€‚ã§çµ‚ã‚ã‚‰ãªã„ï¼‰
            if not text.endswith('ã€‚'):
                invalid.append(i)
                continue

        # ç„¡åŠ¹ãªå•é¡Œã‚’å‰Šé™¤
        original_count = len(self.problems)
        self.problems = [p for i, p in enumerate(self.problems) if i not in invalid]
        deleted = original_count - len(self.problems)

        if deleted > 0:
            print(f"  âš ï¸ {deleted}å•ã®ç„¡åŠ¹ãªå•é¡Œã‚’å‰Šé™¤")
            self.improvements['deleted'] += deleted

    def save_refined(self):
        """æ”¹å–„å¾Œã®å•é¡Œã‚’ä¿å­˜"""
        print("\nğŸ’¾ æ”¹å–„å¾Œã®å•é¡Œã‚’ä¿å­˜ä¸­...")

        # IDã‚’æŒ¯ã‚Šç›´ã—
        for i, problem in enumerate(self.problems, 1):
            problem['problem_id'] = i

        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã‚’è¨ˆç®—
        from collections import Counter
        category_counts = Counter(p['category'] for p in self.problems)
        answer_counts = Counter(p['correct_answer'] for p in self.problems)

        metadata = {
            "generated_at": "2025-10-22T19:00:00",
            "version": "REFINED_670_v1.0",
            "source": "PROBLEMS_IMPROVED_824.json",
            "total_problems": len(self.problems),
            "improvements": {
                "uniqueness_improved": self.improvements['uniqueness'],
                "specificity_improved": self.improvements['specificity'],
                "deleted_problems": self.improvements['deleted'],
                "final_count": len(self.problems)
            },
            "category_distribution": dict(category_counts),
            "answer_distribution": dict(answer_counts)
        }

        data = {
            "metadata": metadata,
            "problems": self.problems
        }

        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"  âœ… {OUTPUT_FILE} ã«ä¿å­˜")
        print(f"\nğŸ“Š æœ€çµ‚çµ±è¨ˆ:")
        print(f"  - å…ƒã®å•é¡Œæ•°: 670å•")
        print(f"  - ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§æ”¹å–„: {self.improvements['uniqueness']}å•")
        print(f"  - å…·ä½“æ€§æ”¹å–„: {self.improvements['specificity']}å•")
        print(f"  - å‰Šé™¤: {self.improvements['deleted']}å•")
        print(f"  - æœ€çµ‚å•é¡Œæ•°: {len(self.problems)}å•")

    def run(self):
        """æ”¹å–„å®Ÿè¡Œ"""
        print("=" * 80)
        print("Worker3 670å•å†ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        print("=" * 80)

        self.load_problems()
        self.improve_uniqueness()
        self.improve_specificity()
        self.final_validation()
        self.save_refined()

        print("\n" + "=" * 80)
        print("âœ… å†ä¿®æ­£å®Œäº†ï¼")
        print("=" * 80)

if __name__ == '__main__':
    refiner = ProblemRefiner()
    refiner.run()
