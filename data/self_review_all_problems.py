#!/usr/bin/env python3
"""
å…¨å•é¡Œã‚»ãƒ«ãƒ•ãƒ¬ãƒ“ãƒ¥ãƒ¼ - Claude Code ã«ã‚ˆã‚‹å“è³ªç¢ºèª
"""

import json
from pathlib import Path
from collections import defaultdict

PROBLEMS_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_REBALANCED_1617.json")

def load_problems():
    with open(PROBLEMS_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def check_problem_quality(problem, problem_num):
    """1å•ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯"""
    issues = []

    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèª
    required_fields = ['problem_id', 'problem_text', 'correct_answer', 'explanation', 'category']
    for field in required_fields:
        if field not in problem:
            issues.append(f"âŒ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒæ¬ è½")

    if not issues:
        # å•é¡Œæ–‡ã®ç¢ºèª
        text = problem.get('problem_text', '')

        # 1. æ„å‘³ä¸æ˜ã§ãªã„ã‹ï¼ˆä¸­èº«ãŒãªã„ãƒ†ã‚­ã‚¹ãƒˆï¼‰
        if not text or len(text.strip()) < 5:
            issues.append(f"âŒ å•é¡Œæ–‡ãŒçŸ­ã™ãã‚‹: '{text}'")

        # 2. å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ›–æ˜§ãªè¡¨ç¾ï¼‰
        vague_words = ['ãªã©', 'ã‚‚ã®ãªã©', 'ã¨ã‹', 'ã„ã‚ã„ã‚', 'æ§˜ã€…', 'ã„ãã¤ã‹']
        if any(word in text for word in vague_words):
            # ã€Œãªã©ã€ã€Œæ§˜ã€…ã€ã¯OKï¼ˆæ³•å¾‹ç”¨èªã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ï¼‰
            # ã§ã‚‚ç•°å¸¸ã«å¤šã„ã®ã¯NG
            vague_count = sum(text.count(word) for word in vague_words)
            if vague_count > 2:
                issues.append(f"âš ï¸  æ›–æ˜§ãªè¡¨ç¾ãŒå¤šã„: '{text}'")

        # 3. æ­£ç­”ç¢ºèª
        answer = problem.get('correct_answer', '')
        if answer not in ['â—‹', 'Ã—']:
            issues.append(f"âŒ æ­£ç­”ãŒä¸æ­£: '{answer}'ï¼ˆâ—‹ã‹Ã—ã§ã‚ã‚‹ã¹ãï¼‰")

        # 4. èª¬æ˜ç¢ºèª
        explanation = problem.get('explanation', '')
        if not explanation or len(explanation.strip()) < 5:
            issues.append(f"âŒ èª¬æ˜ãŒä¸è¶³: '{explanation}'")

        # 5. ã‚«ãƒ†ã‚´ãƒªç¢ºèª
        category = problem.get('category', '')
        valid_categories = ['éŠæŠ€æ©Ÿç®¡ç†', 'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶', 'å–¶æ¥­è¨±å¯é–¢é€£',
                           'å‹å¼æ¤œå®šé–¢é€£', 'ä¸æ­£å¯¾ç­–', 'æ™¯å“è¦åˆ¶']
        if category not in valid_categories:
            issues.append(f"âŒ ç„¡åŠ¹ãªã‚«ãƒ†ã‚´ãƒª: '{category}'")

    return issues

def check_duplicates(problems):
    """é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
    text_map = defaultdict(list)
    duplicates = []

    for idx, problem in enumerate(problems):
        text = problem.get('problem_text', '')
        text_map[text].append(idx + 1)

    for text, problem_ids in text_map.items():
        if len(problem_ids) > 1:
            duplicates.append({
                'text': text,
                'problem_ids': problem_ids
            })

    return duplicates

def main():
    print("=" * 80)
    print("å…¨å•é¡Œã‚»ãƒ«ãƒ•ãƒ¬ãƒ“ãƒ¥ãƒ¼ - Claude Code")
    print("=" * 80)

    data = load_problems()
    problems = data['problems']
    total = len(problems)

    print(f"\nğŸ“Š å¯¾è±¡: å…¨{total}å•\n")

    # ======== 1. å€‹åˆ¥å•é¡Œãƒã‚§ãƒƒã‚¯ ========
    print("1ï¸âƒ£  å€‹åˆ¥å•é¡Œã®å“è³ªãƒã‚§ãƒƒã‚¯ä¸­...")
    problem_issues = []

    for idx, problem in enumerate(problems, 1):
        issues = check_problem_quality(problem, idx)
        if issues:
            problem_issues.append((idx, issues))

        if idx % 200 == 0:
            print(f"   âœ“ {idx}/{total} ç¢ºèªæ¸ˆã¿")

    if problem_issues:
        print(f"\nâŒ å•é¡ŒãŒè¦‹ã¤ã‹ã£ãŸå•é¡Œæ•°: {len(problem_issues)}")
        for problem_id, issues in problem_issues[:10]:  # æœ€åˆã®10ä»¶è¡¨ç¤º
            print(f"\n   ã€å•é¡ŒID {problem_id}ã€‘")
            for issue in issues:
                print(f"      {issue}")
        if len(problem_issues) > 10:
            print(f"\n   âš ï¸  ä»– {len(problem_issues) - 10} ä»¶ã®å•é¡Œã‚ã‚Š")
    else:
        print(f"âœ… ã™ã¹ã¦ã®å•é¡ŒãŒåˆæ ¼ï¼")

    # ======== 2. é‡è¤‡ãƒã‚§ãƒƒã‚¯ ========
    print("\n2ï¸âƒ£  é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
    duplicates = check_duplicates(problems)

    if duplicates:
        print(f"\nâŒ é‡è¤‡ãŒè¦‹ã¤ã‹ã£ãŸ: {len(duplicates)}")
        for dup in duplicates[:5]:
            print(f"   å•é¡ŒID {dup['problem_ids']}: '{dup['text'][:50]}...'")
        if len(duplicates) > 5:
            print(f"   ä»– {len(duplicates) - 5} ä»¶ã®é‡è¤‡ã‚ã‚Š")
    else:
        print(f"âœ… é‡è¤‡ãªã—ï¼")

    # ======== 3. ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒç¢ºèª ========
    print("\n3ï¸âƒ£  ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒç¢ºèªä¸­...")
    category_counts = defaultdict(int)
    for problem in problems:
        category_counts[problem.get('category', 'unknown')] += 1

    target = {
        'éŠæŠ€æ©Ÿç®¡ç†': 596,
        'å–¶æ¥­æ™‚é–“ãƒ»è¦åˆ¶': 224,
        'å–¶æ¥­è¨±å¯é–¢é€£': 194,
        'å‹å¼æ¤œå®šé–¢é€£': 179,
        'ä¸æ­£å¯¾ç­–': 149,
        'æ™¯å“è¦åˆ¶': 149
    }

    all_match = True
    for category in sorted(target.keys()):
        actual = category_counts[category]
        expected = target[category]
        match = actual == expected
        symbol = "âœ…" if match else "âŒ"
        print(f"   {symbol} {category}: {actual}/{expected}")
        if not match:
            all_match = False

    # ======== 4. ç·åˆåˆ¤å®š ========
    print("\n" + "=" * 80)

    issue_count = len(problem_issues)
    duplicate_count = len(duplicates)

    if issue_count == 0 and duplicate_count == 0 and all_match:
        print("âœ… ã€å…¨å•é¡Œã‚»ãƒ«ãƒ•ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆæ ¼ã€‘")
        print(f"   ç·å•é¡Œæ•°: {total}å•")
        print(f"   å€‹åˆ¥å•é¡Œ: âœ… å…¨å•åˆæ ¼")
        print(f"   é‡è¤‡: âœ… ãªã—")
        print(f"   ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: âœ… å®Œå…¨ä¸€è‡´")
        print(f"   ã€çµè«–ã€‘å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å“è³ªã¯è‰¯å¥½ã§ã™ã€‚æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ã€‚")
    else:
        print("âš ï¸  ã€ã‚»ãƒ«ãƒ•ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼šä¿®æ­£å¿…è¦ã€‘")
        if issue_count > 0:
            print(f"   å•é¡Œ: âŒ {issue_count}å•ã«å•é¡Œã‚ã‚Š")
        if duplicate_count > 0:
            print(f"   é‡è¤‡: âŒ {duplicate_count}å€‹ã®é‡è¤‡ã‚ã‚Š")
        if not all_match:
            print(f"   åˆ†å¸ƒ: âŒ ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒãŒä¸€è‡´ã—ã¦ã„ãªã„")
        print(f"   ã€çµè«–ã€‘ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

    print("=" * 80 + "\n")

    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    if problem_issues or duplicates:
        with open('/home/planj/patshinko-exam-app/data/SELF_REVIEW_ISSUES.json', 'w', encoding='utf-8') as f:
            json.dump({
                'problem_issues': [
                    {'problem_id': pid, 'issues': issues}
                    for pid, issues in problem_issues
                ],
                'duplicates': duplicates
            }, f, ensure_ascii=False, indent=2)
        print("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: /home/planj/patshinko-exam-app/data/SELF_REVIEW_ISSUES.json\n")

if __name__ == '__main__':
    main()
