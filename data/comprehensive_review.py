#!/usr/bin/env python3
"""
Worker3ã«ã‚ˆã‚‹å…¨å•ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ1,510å•ï¼‰
å“è³ªæ¤œè¨¼ï¼šæ„å‘³ä¸æ˜ãƒ»æŠ½è±¡çš„ãƒ»é‡è¤‡ãƒ»æ­£ç­”å¦¥å½“æ€§
"""

import json
import re
from pathlib import Path
from collections import defaultdict, Counter
from difflib import SequenceMatcher

INPUT_FILE = Path("/home/planj/patshinko-exam-app/data/PROBLEMS_FINAL_1491_v2.json")
OUTPUT_REPORT = Path("/tmp/worker3_comprehensive_review.md")

# ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸºæº–
ABSTRACT_KEYWORDS = [
    "é‡è¦", "å¿…è¦", "é©åˆ‡", "æ­£ã—ã„", "æœ›ã¾ã—ã„", "ä¸€èˆ¬çš„",
    "åŸºæœ¬", "åŸå‰‡", "é€šå¸¸", "æ¨™æº–", "é€šä¾‹", "æ™®é€š"
]

VAGUE_PATTERNS = [
    r"^.{0,30}ã¯ã€.*ã§ã‚ã‚‹ã€‚$",  # çŸ­ã™ãã‚‹å•é¡Œæ–‡
    r"ã«ã¤ã„ã¦.*çŸ¥è­˜.*ã§ã‚ã‚‹",    # æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³
    r"ã«ã¤ã„ã¦.*ç†è§£.*ã§ã‚ã‚‹",    # æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³
]

class ComprehensiveReviewer:
    def __init__(self):
        self.problems = []
        self.issues = defaultdict(list)
        self.stats = {}

    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰"""
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ä¸­...")
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.problems = data['problems']
        self.metadata = data.get('metadata', {})
        print(f"  âœ… {len(self.problems)}å•ã‚’ãƒ­ãƒ¼ãƒ‰")

    def check_meaningless(self):
        """æ„å‘³ä¸æ˜ãªå•é¡Œã®æ¤œå‡º"""
        print("\nğŸ” æ„å‘³ä¸æ˜ãªå•é¡Œæ–‡ã®æ¤œå‡ºä¸­...")

        for p in self.problems:
            text = p.get('problem_text', '')
            pid = p.get('problem_id')

            # æ¥µç«¯ã«çŸ­ã„
            if len(text) < 20:
                self.issues['too_short'].append({
                    'id': pid,
                    'text': text,
                    'reason': f'å•é¡Œæ–‡ãŒçŸ­ã™ãã‚‹ï¼ˆ{len(text)}æ–‡å­—ï¼‰'
                })

            # æ¥µç«¯ã«é•·ã„
            if len(text) > 500:
                self.issues['too_long'].append({
                    'id': pid,
                    'text': text[:100] + '...',
                    'reason': f'å•é¡Œæ–‡ãŒé•·ã™ãã‚‹ï¼ˆ{len(text)}æ–‡å­—ï¼‰'
                })

            # å¥èª­ç‚¹ãªã—
            if len(text) > 50 and 'ã€' not in text and 'ã€‚' not in text:
                self.issues['no_punctuation'].append({
                    'id': pid,
                    'text': text[:100],
                    'reason': 'å¥èª­ç‚¹ãŒä¸è¶³'
                })

            # æ„å‘³ä¸æ˜ãªæ–‡å­—åˆ—
            if re.search(r'[{}ã€ã€‘\[\]]', text):
                self.issues['template_residue'].append({
                    'id': pid,
                    'text': text,
                    'reason': 'ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ®‹éª¸ã®å¯èƒ½æ€§'
                })

        print(f"  âš ï¸  çŸ­ã™ãã‚‹å•é¡Œ: {len(self.issues['too_short'])}å•")
        print(f"  âš ï¸  é•·ã™ãã‚‹å•é¡Œ: {len(self.issues['too_long'])}å•")
        print(f"  âš ï¸  å¥èª­ç‚¹ä¸è¶³: {len(self.issues['no_punctuation'])}å•")
        print(f"  âš ï¸  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ®‹éª¸: {len(self.issues['template_residue'])}å•")

    def check_abstract(self):
        """æŠ½è±¡çš„ã™ãã‚‹å•é¡Œã®æ¤œå‡º"""
        print("\nğŸ” æŠ½è±¡çš„ã™ãã‚‹å•é¡Œæ–‡ã®æ¤œå‡ºä¸­...")

        for p in self.problems:
            text = p.get('problem_text', '')
            pid = p.get('problem_id')

            # æŠ½è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆ
            abstract_count = sum(1 for kw in ABSTRACT_KEYWORDS if kw in text)

            if abstract_count >= 3:
                self.issues['too_abstract'].append({
                    'id': pid,
                    'text': text,
                    'reason': f'æŠ½è±¡çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå¤šã„ï¼ˆ{abstract_count}å€‹ï¼‰',
                    'keywords': [kw for kw in ABSTRACT_KEYWORDS if kw in text]
                })

            # æ›–æ˜§ãƒ‘ã‚¿ãƒ¼ãƒ³
            for pattern in VAGUE_PATTERNS:
                if re.match(pattern, text):
                    self.issues['vague_pattern'].append({
                        'id': pid,
                        'text': text,
                        'reason': f'æ›–æ˜§ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ{pattern}ï¼‰'
                    })
                    break

        print(f"  âš ï¸  æŠ½è±¡çš„ã™ãã‚‹: {len(self.issues['too_abstract'])}å•")
        print(f"  âš ï¸  æ›–æ˜§ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.issues['vague_pattern'])}å•")

    def check_specificity(self):
        """å…·ä½“æ€§ã®æ¤œè¨¼"""
        print("\nğŸ” å…·ä½“æ€§ã®æ¬ å¦‚ã‚’æ¤œå‡ºä¸­...")

        for p in self.problems:
            text = p.get('problem_text', '')
            pid = p.get('problem_id')

            # å…·ä½“çš„ãªè¦ç´ ã®æœ‰ç„¡ãƒã‚§ãƒƒã‚¯
            has_number = bool(re.search(r'\d+', text))
            has_specific_term = bool(re.search(r'(ç¬¬\d+æ¡|å…¬å®‰å§”å“¡ä¼š|é¢¨å–¶æ³•|æ¤œå®š|å‹å¼|éŠæŠ€æ©Ÿ|å–¶æ¥­æ‰€)', text))
            has_action = bool(re.search(r'(è¨­ç½®|äº¤æ›|ç”³è«‹|å±Šå‡º|ç¢ºèª|ç‚¹æ¤œ|ç®¡ç†|å ±å‘Š)', text))

            specificity_score = sum([has_number, has_specific_term, has_action])

            if specificity_score == 0:
                self.issues['no_specificity'].append({
                    'id': pid,
                    'text': text,
                    'reason': 'å…·ä½“çš„è¦ç´ ãŒçš†ç„¡'
                })
            elif specificity_score == 1:
                self.issues['low_specificity'].append({
                    'id': pid,
                    'text': text,
                    'reason': 'å…·ä½“æ€§ãŒä½ã„'
                })

        print(f"  âš ï¸  å…·ä½“æ€§çš†ç„¡: {len(self.issues['no_specificity'])}å•")
        print(f"  âš ï¸  å…·ä½“æ€§ä½: {len(self.issues['low_specificity'])}å•")

    def check_duplicates(self):
        """é‡è¤‡ã®å†ç¢ºèªï¼ˆé«˜é¡ä¼¼åº¦ï¼‰"""
        print("\nğŸ” é«˜é¡ä¼¼åº¦å•é¡Œã®æ¤œå‡ºä¸­ï¼ˆ90%ä»¥ä¸Šï¼‰...")

        duplicate_pairs = []

        for i, p1 in enumerate(self.problems):
            if i % 200 == 0:
                print(f"  é€²æ—: {i}/{len(self.problems)}å•")

            text1 = p1.get('problem_text', '')
            id1 = p1.get('problem_id')

            for p2 in self.problems[i+1:]:
                text2 = p2.get('problem_text', '')
                id2 = p2.get('problem_id')

                similarity = SequenceMatcher(None, text1, text2).ratio()

                if similarity >= 0.90:
                    duplicate_pairs.append({
                        'id1': id1,
                        'id2': id2,
                        'similarity': similarity,
                        'text1': text1,
                        'text2': text2
                    })

        self.issues['high_similarity'] = duplicate_pairs
        print(f"  âš ï¸  é«˜é¡ä¼¼åº¦ï¼ˆ90%+ï¼‰: {len(duplicate_pairs)}ãƒšã‚¢")

    def check_answers(self):
        """æ­£ç­”ãƒ»è§£èª¬ã®å¦¥å½“æ€§æ¤œè¨¼"""
        print("\nğŸ” æ­£ç­”ãƒ»è§£èª¬ã®å¦¥å½“æ€§æ¤œè¨¼ä¸­...")

        for p in self.problems:
            pid = p.get('problem_id')
            answer = p.get('correct_answer')
            explanation = p.get('explanation', '')
            text = p.get('problem_text', '')

            # æ­£ç­”ãŒæœªè¨­å®š
            if not answer:
                self.issues['no_answer'].append({
                    'id': pid,
                    'text': text,
                    'reason': 'æ­£ç­”ãŒæœªè¨­å®š'
                })

            # æ­£ç­”ãŒâ—‹Ã—ä»¥å¤–
            if answer not in ['â—‹', 'Ã—']:
                self.issues['invalid_answer'].append({
                    'id': pid,
                    'text': text,
                    'answer': answer,
                    'reason': f'ä¸æ­£ãªæ­£ç­”å½¢å¼ï¼ˆ{answer}ï¼‰'
                })

            # è§£èª¬ãŒçŸ­ã™ãã‚‹
            if len(explanation) < 10:
                self.issues['short_explanation'].append({
                    'id': pid,
                    'text': text,
                    'explanation': explanation,
                    'reason': f'è§£èª¬ãŒçŸ­ã™ãã‚‹ï¼ˆ{len(explanation)}æ–‡å­—ï¼‰'
                })

            # è§£èª¬ãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçš„
            if 'æ­£ç¢ºã«ç†è§£' in explanation or 'åŸºæœ¬ã§ã™' in explanation:
                self.issues['template_explanation'].append({
                    'id': pid,
                    'text': text[:50],
                    'explanation': explanation,
                    'reason': 'ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçš„è§£èª¬'
                })

        print(f"  âš ï¸  æ­£ç­”æœªè¨­å®š: {len(self.issues['no_answer'])}å•")
        print(f"  âš ï¸  ä¸æ­£ãªæ­£ç­”: {len(self.issues['invalid_answer'])}å•")
        print(f"  âš ï¸  è§£èª¬çŸ­ã™ã: {len(self.issues['short_explanation'])}å•")
        print(f"  âš ï¸  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè§£èª¬: {len(self.issues['template_explanation'])}å•")

    def check_distribution(self):
        """ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ†ãƒ¼ãƒåˆ†å¸ƒã®æ¤œè¨¼"""
        print("\nğŸ” ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ†ãƒ¼ãƒåˆ†å¸ƒã®æ¤œè¨¼ä¸­...")

        categories = Counter(p.get('category') for p in self.problems)
        themes = Counter(p.get('theme_name') for p in self.problems)
        difficulties = Counter(p.get('difficulty') for p in self.problems)

        self.stats['categories'] = dict(categories)
        self.stats['themes'] = dict(themes)
        self.stats['difficulties'] = dict(difficulties)

        print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"  {cat}: {count}å• ({count/len(self.problems)*100:.1f}%)")

        print(f"\nğŸ“Š é›£æ˜“åº¦åˆ†å¸ƒ:")
        for diff, count in sorted(difficulties.items()):
            print(f"  {diff}: {count}å• ({count/len(self.problems)*100:.1f}%)")

        print(f"\nğŸ“Š ãƒ†ãƒ¼ãƒæ•°: {len(themes)}ãƒ†ãƒ¼ãƒ")

        # 0å•ãƒ†ãƒ¼ãƒã®æ¤œå‡º
        zero_themes = [theme for theme, count in themes.items() if count == 0]
        if zero_themes:
            self.issues['zero_themes'] = zero_themes
            print(f"  âš ï¸  0å•ãƒ†ãƒ¼ãƒ: {len(zero_themes)}ãƒ†ãƒ¼ãƒ")

    def generate_report(self):
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\nğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")

        report = "# Worker3 å…¨å•ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆï¼ˆ1,510å•ï¼‰\n\n"
        report += "**ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥**: 2025-10-22\n"
        report += "**ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼**: Worker3ï¼ˆClaude Code - Sonnet 4.5ï¼‰\n"
        report += f"**å¯¾è±¡**: {len(self.problems)}å•\n\n"
        report += "---\n\n"

        # ç·åˆè©•ä¾¡
        total_issues = sum(len(v) if isinstance(v, list) else 0 for v in self.issues.values())

        report += "## âœ… ç·åˆè©•ä¾¡\n\n"

        if total_issues == 0:
            report += "**åˆ¤å®š**: âœ… **EXCELLENT - å•é¡Œãªã—**\n\n"
        elif total_issues < 50:
            report += f"**åˆ¤å®š**: ğŸŸ¡ **GOOD - è»½å¾®ãªå•é¡Œã‚ã‚Šï¼ˆ{total_issues}ä»¶ï¼‰**\n\n"
        elif total_issues < 200:
            report += f"**åˆ¤å®š**: âš ï¸ **WARNING - è¦æ”¹å–„ï¼ˆ{total_issues}ä»¶ï¼‰**\n\n"
        else:
            report += f"**åˆ¤å®š**: âŒ **CRITICAL - é‡å¤§å•é¡Œï¼ˆ{total_issues}ä»¶ï¼‰**\n\n"

        report += f"**æ¤œå‡ºã•ã‚ŒãŸå•é¡Œç·æ•°**: {total_issues}ä»¶\n\n"
        report += "---\n\n"

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œæ•°
        report += "## ğŸ“Š æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã®å†…è¨³\n\n"
        report += "| ã‚«ãƒ†ã‚´ãƒª | ä»¶æ•° | é‡è¦åº¦ |\n"
        report += "|---------|------|--------|\n"

        issue_categories = {
            'template_residue': ('ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ®‹éª¸', 'ğŸ”´ HIGH'),
            'no_answer': ('æ­£ç­”æœªè¨­å®š', 'ğŸ”´ HIGH'),
            'invalid_answer': ('ä¸æ­£ãªæ­£ç­”', 'ğŸ”´ HIGH'),
            'high_similarity': ('é«˜é¡ä¼¼åº¦ï¼ˆ90%+ï¼‰', 'ğŸ”´ HIGH'),
            'no_specificity': ('å…·ä½“æ€§çš†ç„¡', 'ğŸŸ¡ MEDIUM'),
            'too_abstract': ('æŠ½è±¡çš„ã™ã', 'ğŸŸ¡ MEDIUM'),
            'vague_pattern': ('æ›–æ˜§ãƒ‘ã‚¿ãƒ¼ãƒ³', 'ğŸŸ¡ MEDIUM'),
            'low_specificity': ('å…·ä½“æ€§ä½', 'ğŸŸ¢ LOW'),
            'short_explanation': ('è§£èª¬çŸ­ã™ã', 'ğŸŸ¢ LOW'),
            'template_explanation': ('ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè§£èª¬', 'ğŸŸ¢ LOW'),
            'too_short': ('å•é¡Œæ–‡çŸ­ã™ã', 'ğŸŸ¢ LOW'),
            'too_long': ('å•é¡Œæ–‡é•·ã™ã', 'ğŸŸ¢ LOW'),
            'no_punctuation': ('å¥èª­ç‚¹ä¸è¶³', 'ğŸŸ¢ LOW'),
        }

        for key, (name, priority) in issue_categories.items():
            count = len(self.issues.get(key, []))
            if count > 0:
                report += f"| {name} | {count}ä»¶ | {priority} |\n"

        report += "\n---\n\n"

        # è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        report += "## ğŸ” å•é¡Œè©³ç´°\n\n"

        # HIGHå„ªå…ˆåº¦ã®å•é¡Œã‚’è©³ç´°è¡¨ç¤º
        if self.issues['template_residue']:
            report += "### ğŸ”´ HIGH: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ®‹éª¸\n\n"
            for issue in self.issues['template_residue'][:10]:
                report += f"**å•é¡ŒID {issue['id']}**:\n"
                report += f"- å•é¡Œæ–‡: {issue['text']}\n"
                report += f"- ç†ç”±: {issue['reason']}\n\n"
            if len(self.issues['template_residue']) > 10:
                report += f"*ï¼ˆæ®‹ã‚Š{len(self.issues['template_residue'])-10}ä»¶ï¼‰*\n\n"

        if self.issues['high_similarity']:
            report += "### ğŸ”´ HIGH: é«˜é¡ä¼¼åº¦å•é¡Œï¼ˆ90%ä»¥ä¸Šï¼‰\n\n"
            for pair in self.issues['high_similarity'][:10]:
                report += f"**å•é¡ŒID {pair['id1']} â‡” {pair['id2']}** (é¡ä¼¼åº¦: {pair['similarity']:.2%})\n"
                report += f"- å•é¡Œ1: {pair['text1'][:100]}...\n"
                report += f"- å•é¡Œ2: {pair['text2'][:100]}...\n\n"
            if len(self.issues['high_similarity']) > 10:
                report += f"*ï¼ˆæ®‹ã‚Š{len(self.issues['high_similarity'])-10}ãƒšã‚¢ï¼‰*\n\n"

        # çµ±è¨ˆæƒ…å ±
        report += "---\n\n"
        report += "## ğŸ“Š çµ±è¨ˆæƒ…å ±\n\n"

        report += "### ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n\n"
        for cat, count in sorted(self.stats['categories'].items(), key=lambda x: x[1], reverse=True):
            report += f"- {cat}: {count}å• ({count/len(self.problems)*100:.1f}%)\n"

        report += "\n### é›£æ˜“åº¦åˆ†å¸ƒ\n\n"
        for diff, count in sorted(self.stats['difficulties'].items()):
            report += f"- {diff}: {count}å• ({count/len(self.problems)*100:.1f}%)\n"

        report += f"\n### ãƒ†ãƒ¼ãƒæ•°\n\n"
        report += f"- ç·ãƒ†ãƒ¼ãƒæ•°: {len(self.stats['themes'])}ãƒ†ãƒ¼ãƒ\n"

        # æœ€çµ‚åˆ¤å®š
        report += "\n---\n\n"
        report += "## ğŸ¯ æœ€çµ‚åˆ¤å®š\n\n"

        critical_issues = (
            len(self.issues['template_residue']) +
            len(self.issues['no_answer']) +
            len(self.issues['invalid_answer'])
        )

        if critical_issues == 0 and len(self.issues['high_similarity']) == 0:
            report += "**æœ¬ç•ªæŠ•å…¥**: âœ… **å¯èƒ½**\n\n"
            report += "é‡å¤§ãªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"
        elif critical_issues < 10:
            report += "**æœ¬ç•ªæŠ•å…¥**: ğŸŸ¡ **æ¡ä»¶ä»˜ãå¯èƒ½**\n\n"
            report += f"è»½å¾®ãªå•é¡Œï¼ˆ{critical_issues}ä»¶ï¼‰ã®ä¿®æ­£å¾Œã€æœ¬ç•ªæŠ•å…¥å¯èƒ½ã§ã™ã€‚\n"
        else:
            report += "**æœ¬ç•ªæŠ•å…¥**: âŒ **è¦ä¿®æ­£**\n\n"
            report += f"é‡å¤§ãªå•é¡Œï¼ˆ{critical_issues}ä»¶ï¼‰ã®ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚\n"

        report += "\n---\n\n"
        report += "**ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼**: Worker3ï¼ˆClaude Code - Sonnet 4.5ï¼‰\n"
        report += "**ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥æ™‚**: 2025-10-22\n"

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"  âœ… ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {OUTPUT_REPORT}")

    def run(self):
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ"""
        print("=" * 80)
        print("Worker3 å…¨å•ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ1,510å•ï¼‰")
        print("=" * 80)

        self.load_data()
        self.check_meaningless()
        self.check_abstract()
        self.check_specificity()
        self.check_duplicates()
        self.check_answers()
        self.check_distribution()
        self.generate_report()

        print("\n" + "=" * 80)
        print("âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†ï¼")
        print("=" * 80)


if __name__ == '__main__':
    reviewer = ComprehensiveReviewer()
    reviewer.run()
