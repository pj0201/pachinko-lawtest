#!/usr/bin/env python3
"""
OCRèª¤å­—è‡ªå‹•ä¿®æ­£ãƒ„ãƒ¼ãƒ«
æ¤œå‡ºã•ã‚ŒãŸèª¤å­—ã‚’è‡ªå‹•ç½®æ›ã—ã¦ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
"""

import json
import re
from pathlib import Path

OCR_FILE = Path("/home/planj/patshinko-exam-app/data/ocr_results.json")
OUTPUT_FILE = Path("/home/planj/patshinko-exam-app/data/ocr_results_corrected.json")

# ==================== ä¿®æ­£ãƒ«ãƒ¼ãƒ« ====================

CORRECTION_RULES = {
    # é«˜é »åº¦ãƒ»é«˜é‡è¦åº¦ã®èª¤å­—
    'éŠæŠ«æ©Ÿ': 'éŠæŠ€æ©Ÿ',
    'éŠæŠ«': 'éŠæŠ€',
    'åº•æŠ€æ©Ÿ': 'éŠæŠ€æ©Ÿ',
    'ä½œæŠ€æ©Ÿ': 'éŠæŠ€æ©Ÿ',
    'éŠå®Ÿæ©Ÿ': 'éŠæŠ€æ©Ÿ',
    'å™æ©Ÿ': 'éŠæŠ€æ©Ÿ',
    'éŠæ•·æ©Ÿ': 'éŠæŠ€æ©Ÿ',

    # ç¢ºèªç³»
    'ç¨šèª': 'ç¢ºèª',
    'æ’®èª': 'ç¢ºèª',
    'ç¢ºæ€': 'ç¢ºèª',

    # è¦åˆ¶ç³»
    'è¦ªåˆ¶': 'è¦åˆ¶',
    'è¢«åˆ¶': 'è¦åˆ¶',

    # æ¥­ç•Œç³»
    'äº‹è‘‰': 'æ¥­ç•Œ',

    # å–¶æ¥­ç³»
    'å–¶ç¾½æ¥­': 'å–¶æ¥­',

    # è¨˜å·ãƒ»æ•°å­—ã®å‘¨å›²ã‚¹ãƒšãƒ¼ã‚¹ä¿®æ­£ï¼ˆå¾Œå‡¦ç†ï¼‰
}

# ==================== ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•° ====================

def clean_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""

    # 1. åŸºæœ¬çš„ãªèª¤å­—ç½®æ›
    for wrong, correct in CORRECTION_RULES.items():
        # å˜èªå˜ä½ã§ã®ç½®æ›ï¼ˆå‰å¾ŒãŒéæ–‡å­—ãªã‚‰OKï¼‰
        pattern = r'(?<![a-zA-Z0-9])' + re.escape(wrong) + r'(?![a-zA-Z0-9])'
        text = re.sub(pattern, correct, text)

    # 2. O/0 æ··åŒã®ä¿®æ­£ï¼ˆæ–‡è„ˆã‹ã‚‰åˆ¤æ–­ï¼‰
    # ä¾‹: "Oå¹´" â†’ "0å¹´", "0å€‹" â†’ "0å€‹" ãªã©
    # ãŸã ã—ã€Œé¢¨ä¿—ã€ã®ã€Œâ—‹ã€ã¯ã€Œâ—‹ã€ã®ã¾ã¾ã«ã—ã¦ãŠã

    # 3. æ”¹è¡Œãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–
    # è¤‡æ•°ã®æ”¹è¡Œã‚’1ã¤ã«
    text = re.sub(r'\n\n+', '\n', text)

    # 4. é‡è¤‡ã™ã‚‹å¥ç‚¹ã®ä¿®æ­£
    text = text.replace('ã€‚ã€‚', 'ã€‚')
    text = text.replace('ã€ã€', 'ã€')

    # 5. æ•°å­—ã®å‰å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹æ­£è¦åŒ–
    # ã€Œ1234ã€ã€Œ5678ã€ã®å½¢å¼ã¯ä¿æŒã€ã€Œ12 34ã€ã¯ä¿®æ­£

    return text

def process_ocr_results():
    """OCRçµæœå…¨ä½“ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    print("=" * 80)
    print("ğŸ”§ OCRè‡ªå‹•ä¿®æ­£å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 80)

    # OCRçµæœã‚’èª­ã¿è¾¼ã¿
    with open(OCR_FILE, 'r', encoding='utf-8') as f:
        results = json.load(f)

    print(f"\nğŸ“ å…¥åŠ›: {len(results)}ãƒšãƒ¼ã‚¸")

    # ä¿®æ­£çµ±è¨ˆ
    stats = {
        'total_corrections': 0,
        'corrections_by_type': {},
        'pages_modified': 0
    }

    # å„ãƒšãƒ¼ã‚¸ã‚’ä¿®æ­£
    corrected_results = []

    for result in results:
        original_text = result.get('text', '')
        corrected_text = clean_text(original_text)

        # ä¿®æ­£ãŒã‚ã£ãŸã‹ç¢ºèª
        if original_text != corrected_text:
            stats['pages_modified'] += 1

            # ä¿®æ­£å†…å®¹ã‚’è¨˜éŒ²
            for wrong, correct in CORRECTION_RULES.items():
                count = original_text.count(wrong) - corrected_text.count(wrong)
                if count > 0:
                    key = f"{wrong}â†’{correct}"
                    stats['corrections_by_type'][key] = \
                        stats['corrections_by_type'].get(key, 0) + count
                    stats['total_corrections'] += count

        corrected_results.append({
            **result,
            'text': corrected_text,
            'corrected': original_text != corrected_text
        })

    # ä¿®æ­£çµæœã‚’ä¿å­˜
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(corrected_results, f, indent=2, ensure_ascii=False)

    # çµ±è¨ˆè¡¨ç¤º
    print(f"\nâœ… ä¿®æ­£å®Œäº†")
    print(f"   ä¿®æ­£å¯¾è±¡ãƒšãƒ¼ã‚¸: {stats['pages_modified']}/{len(results)}")
    print(f"   ç·ä¿®æ­£ç®‡æ‰€: {stats['total_corrections']}ä»¶")

    print(f"\nğŸ“Š ä¿®æ­£å†…å®¹:")
    for correction_type, count in sorted(
        stats['corrections_by_type'].items(),
        key=lambda x: x[1],
        reverse=True
    ):
        print(f"   {correction_type}: {count}ä»¶")

    print(f"\nğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {OUTPUT_FILE}")
    print("=" * 80)

    return stats

# ==================== æ¯”è¼ƒãƒ„ãƒ¼ãƒ« ====================

def compare_samples():
    """ä¿®æ­£å‰å¾Œã‚’æ¯”è¼ƒè¡¨ç¤º"""
    print("\nğŸ“‹ ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰:")
    print("-" * 80)

    with open(OCR_FILE, 'r', encoding='utf-8') as f:
        original = json.load(f)

    with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
        corrected = json.load(f)

    # ä¿®æ­£ãŒã‚ã£ãŸãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    count = 0
    for i, (orig, corr) in enumerate(zip(original, corrected)):
        if orig['text'] != corr['text']:
            if count < 3:  # æœ€åˆã®3ã¤ã®ã¿è¡¨ç¤º
                print(f"\nãƒšãƒ¼ã‚¸ {i+1}:")
                print(f"ä¿®æ­£å‰: {orig['text'][:100]}...")
                print(f"ä¿®æ­£å¾Œ: {corr['text'][:100]}...")
                count += 1

# ==================== ãƒ¡ã‚¤ãƒ³ ====================

if __name__ == '__main__':
    # ä¿®æ­£å®Ÿè¡Œ
    stats = process_ocr_results()

    # ä¿®æ­£å‰å¾Œã‚’æ¯”è¼ƒ
    if OUTPUT_FILE.exists():
        compare_samples()

    print("\nâœ¨ ä¿®æ­£å®Œäº†ï¼")
    print(f"   ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«: ocr_results_corrected.json")
    print(f"   ä»¥é™ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†é¡ãƒ»æ¡ç‚¹ã«ä½¿ç”¨ã—ã¦ãã ã•ã„")
